2023-10-03 19:58:50,956 - INFO - Epoch 0, Training Loss: 0.7221000790596008, Sample loss: 0.7008454203605652, Validation Loss: 0.658699631690979
2023-10-03 19:58:54,584 - INFO - Epoch 1, Training Loss: 0.5607052445411682, Sample loss: 0.5904358625411987, Validation Loss: 0.5151774883270264
2023-10-03 19:58:58,128 - INFO - Epoch 2, Training Loss: 0.4651959538459778, Sample loss: 0.46754175424575806, Validation Loss: 0.41955214738845825
2023-10-03 19:59:01,312 - INFO - Epoch 3, Training Loss: 0.4076983630657196, Sample loss: 0.426952987909317, Validation Loss: 0.3900119364261627
2023-10-03 19:59:05,036 - INFO - Epoch 4, Training Loss: 0.40237119793891907, Sample loss: 0.36315223574638367, Validation Loss: 0.3618925213813782
2023-10-03 19:59:08,621 - INFO - Epoch 5, Training Loss: 0.35837677121162415, Sample loss: 0.3874194025993347, Validation Loss: 0.3537721037864685
2023-10-03 19:59:12,175 - INFO - Epoch 6, Training Loss: 0.3476594388484955, Sample loss: 0.3641512095928192, Validation Loss: 0.3183954656124115
2023-10-03 19:59:15,642 - INFO - Epoch 7, Training Loss: 0.3410840928554535, Sample loss: 0.3668856620788574, Validation Loss: 0.35519254207611084
2023-10-03 19:59:19,100 - INFO - Epoch 8, Training Loss: 0.3119247555732727, Sample loss: 0.30294856429100037, Validation Loss: 0.2846563458442688
2023-10-03 19:59:22,813 - INFO - Epoch 9, Training Loss: 0.32074517011642456, Sample loss: 0.2907157838344574, Validation Loss: 0.31839844584465027
2023-10-03 19:59:26,322 - INFO - Epoch 10, Training Loss: 0.31797200441360474, Sample loss: 0.3090442419052124, Validation Loss: 0.2882222533226013
2023-10-03 19:59:29,825 - INFO - Epoch 11, Training Loss: 0.28202930092811584, Sample loss: 0.3119818866252899, Validation Loss: 0.2817741334438324
2023-10-03 19:59:33,331 - INFO - Epoch 12, Training Loss: 0.3106447458267212, Sample loss: 0.28226548433303833, Validation Loss: 0.28748443722724915
2023-10-03 19:59:36,611 - INFO - Epoch 13, Training Loss: 0.2663285434246063, Sample loss: 0.27158603072166443, Validation Loss: 0.26393401622772217
2023-10-03 19:59:40,245 - INFO - Epoch 14, Training Loss: 0.2679046094417572, Sample loss: 0.28967729210853577, Validation Loss: 0.26339423656463623
2023-10-03 19:59:44,098 - INFO - Epoch 15, Training Loss: 0.24641713500022888, Sample loss: 0.24670955538749695, Validation Loss: 0.25532007217407227
2023-10-03 19:59:47,314 - INFO - Epoch 16, Training Loss: 0.3011096715927124, Sample loss: 0.3065569996833801, Validation Loss: 0.2798618972301483
2023-10-03 19:59:50,956 - INFO - Epoch 17, Training Loss: 0.24188362061977386, Sample loss: 0.24033944308757782, Validation Loss: 0.24421684443950653
2023-10-03 19:59:54,492 - INFO - Epoch 18, Training Loss: 0.27361583709716797, Sample loss: 0.28600209951400757, Validation Loss: 0.28654906153678894
2023-10-03 19:59:58,325 - INFO - Epoch 19, Training Loss: 0.23760069906711578, Sample loss: 0.22812657058238983, Validation Loss: 0.23019163310527802
2023-10-03 20:00:01,964 - INFO - Epoch 20, Training Loss: 0.25306424498558044, Sample loss: 0.24118399620056152, Validation Loss: 0.26935455203056335
2023-10-03 20:00:05,253 - INFO - Epoch 21, Training Loss: 0.23689907789230347, Sample loss: 0.22060680389404297, Validation Loss: 0.22410763800144196
2023-10-03 20:00:08,805 - INFO - Epoch 22, Training Loss: 0.2364317923784256, Sample loss: 0.2710595726966858, Validation Loss: 0.25384747982025146
2023-10-03 20:00:12,004 - INFO - Epoch 23, Training Loss: 0.24652013182640076, Sample loss: 0.21375422179698944, Validation Loss: 0.22781957685947418
2023-10-03 20:00:15,526 - INFO - Epoch 24, Training Loss: 0.22980687022209167, Sample loss: 0.2554178833961487, Validation Loss: 0.24607938528060913
2023-10-03 20:00:19,401 - INFO - Epoch 25, Training Loss: 0.23472730815410614, Sample loss: 0.24211759865283966, Validation Loss: 0.21869637072086334
2023-10-03 20:00:23,077 - INFO - Epoch 26, Training Loss: 0.22434189915657043, Sample loss: 0.2208256721496582, Validation Loss: 0.2510179579257965
2023-10-03 20:00:26,516 - INFO - Epoch 27, Training Loss: 0.24029476940631866, Sample loss: 0.21342165768146515, Validation Loss: 0.23284003138542175
2023-10-03 20:00:29,808 - INFO - Epoch 28, Training Loss: 0.20794902741909027, Sample loss: 0.1838611662387848, Validation Loss: 0.2296215146780014
2023-10-03 20:00:33,241 - INFO - Epoch 29, Training Loss: 0.23421385884284973, Sample loss: 0.20997989177703857, Validation Loss: 0.23775483667850494
2023-10-03 20:00:36,516 - INFO - Epoch 30, Training Loss: 0.2018858790397644, Sample loss: 0.21234185993671417, Validation Loss: 0.22087423503398895
2023-10-03 20:00:39,841 - INFO - Epoch 31, Training Loss: 0.22038276493549347, Sample loss: 0.19421163201332092, Validation Loss: 0.22303487360477448
2023-10-03 20:00:43,096 - INFO - Epoch 32, Training Loss: 0.20571689307689667, Sample loss: 0.19572760164737701, Validation Loss: 0.22473309934139252
2023-10-03 20:00:46,125 - INFO - Epoch 33, Training Loss: 0.20799468457698822, Sample loss: 0.21664032340049744, Validation Loss: 0.22171300649642944
2023-10-03 20:00:49,570 - INFO - Epoch 34, Training Loss: 0.20337390899658203, Sample loss: 0.21430730819702148, Validation Loss: 0.23298725485801697
2023-10-03 20:00:53,049 - INFO - Epoch 35, Training Loss: 0.2113378793001175, Sample loss: 0.21945789456367493, Validation Loss: 0.2225951850414276
2023-10-03 20:00:56,001 - INFO - Epoch 36, Training Loss: 0.19133679568767548, Sample loss: 0.1854950338602066, Validation Loss: 0.22233346104621887
2023-10-03 20:00:59,583 - INFO - Epoch 37, Training Loss: 0.21572786569595337, Sample loss: 0.19727958738803864, Validation Loss: 0.22096173465251923
2023-10-03 20:01:02,864 - INFO - Epoch 38, Training Loss: 0.1923409104347229, Sample loss: 0.20610249042510986, Validation Loss: 0.22128655016422272
2023-10-03 20:01:06,262 - INFO - Epoch 39, Training Loss: 0.209743469953537, Sample loss: 0.22976970672607422, Validation Loss: 0.21702265739440918
2023-10-03 20:01:09,594 - INFO - Epoch 40, Training Loss: 0.2156975120306015, Sample loss: 0.23221726715564728, Validation Loss: 0.25710979104042053
2023-10-03 20:01:12,915 - INFO - Epoch 41, Training Loss: 0.20229697227478027, Sample loss: 0.1902499496936798, Validation Loss: 0.20575574040412903
2023-10-03 20:01:16,071 - INFO - Epoch 42, Training Loss: 0.1900337040424347, Sample loss: 0.19972828030586243, Validation Loss: 0.2150460034608841
2023-10-03 20:01:19,514 - INFO - Epoch 43, Training Loss: 0.19500777125358582, Sample loss: 0.21592147648334503, Validation Loss: 0.21888995170593262
2023-10-03 20:01:22,843 - INFO - Epoch 44, Training Loss: 0.206057608127594, Sample loss: 0.2136465609073639, Validation Loss: 0.2178610861301422
2023-10-03 20:01:26,140 - INFO - Epoch 45, Training Loss: 0.20213626325130463, Sample loss: 0.175449401140213, Validation Loss: 0.24136240780353546
2023-10-03 20:01:29,442 - INFO - Epoch 46, Training Loss: 0.20204925537109375, Sample loss: 0.19268618524074554, Validation Loss: 0.20109567046165466
2023-10-03 20:01:32,687 - INFO - Epoch 47, Training Loss: 0.19353872537612915, Sample loss: 0.16514481604099274, Validation Loss: 0.2351650446653366
2023-10-03 20:01:36,082 - INFO - Epoch 48, Training Loss: 0.20025219023227692, Sample loss: 0.1736517995595932, Validation Loss: 0.19830264151096344
2023-10-03 20:01:39,372 - INFO - Epoch 49, Training Loss: 0.18713785707950592, Sample loss: 0.1986793875694275, Validation Loss: 0.21924661099910736
2023-10-03 20:01:42,784 - INFO - Epoch 50, Training Loss: 0.22345159947872162, Sample loss: 0.21570320427417755, Validation Loss: 0.20730794966220856
2023-10-03 20:01:46,193 - INFO - Epoch 51, Training Loss: 0.1743239015340805, Sample loss: 0.18427574634552002, Validation Loss: 0.21739377081394196
2023-10-03 20:01:49,894 - INFO - Epoch 52, Training Loss: 0.21555238962173462, Sample loss: 0.20076878368854523, Validation Loss: 0.20667454600334167
2023-10-03 20:01:53,690 - INFO - Epoch 53, Training Loss: 0.18269868195056915, Sample loss: 0.18921871483325958, Validation Loss: 0.2185690701007843
2023-10-03 20:01:57,363 - INFO - Epoch 54, Training Loss: 0.19257304072380066, Sample loss: 0.18062642216682434, Validation Loss: 0.19035711884498596
2023-10-03 20:02:00,939 - INFO - Epoch 55, Training Loss: 0.19832433760166168, Sample loss: 0.17807447910308838, Validation Loss: 0.24530790746212006
2023-10-03 20:02:05,023 - INFO - Epoch 56, Training Loss: 0.1816457062959671, Sample loss: 0.1559305042028427, Validation Loss: 0.18967407941818237
2023-10-03 20:02:08,264 - INFO - Epoch 57, Training Loss: 0.1968202292919159, Sample loss: 0.20655854046344757, Validation Loss: 0.24593934416770935
2023-10-03 20:02:12,034 - INFO - Epoch 58, Training Loss: 0.17783324420452118, Sample loss: 0.193524569272995, Validation Loss: 0.18360087275505066
2023-10-03 20:02:15,258 - INFO - Epoch 59, Training Loss: 0.18673856556415558, Sample loss: 0.21952614188194275, Validation Loss: 0.2354859560728073
2023-10-03 20:02:18,426 - INFO - Epoch 60, Training Loss: 0.17058613896369934, Sample loss: 0.15423652529716492, Validation Loss: 0.18070851266384125
2023-10-03 20:02:22,043 - INFO - Epoch 61, Training Loss: 0.1869478076696396, Sample loss: 0.1891171783208847, Validation Loss: 0.22321175038814545
2023-10-03 20:02:25,206 - INFO - Epoch 62, Training Loss: 0.1772233098745346, Sample loss: 0.14423252642154694, Validation Loss: 0.1867419332265854
2023-10-03 20:02:29,206 - INFO - Epoch 63, Training Loss: 0.187669038772583, Sample loss: 0.2021421194076538, Validation Loss: 0.2358420491218567
2023-10-03 20:02:32,793 - INFO - Epoch 64, Training Loss: 0.19907912611961365, Sample loss: 0.14386999607086182, Validation Loss: 0.19566869735717773
2023-10-03 20:02:36,212 - INFO - Epoch 65, Training Loss: 0.18621940910816193, Sample loss: 0.18036022782325745, Validation Loss: 0.23219847679138184
2023-10-03 20:02:39,505 - INFO - Epoch 66, Training Loss: 0.18866826593875885, Sample loss: 0.20162515342235565, Validation Loss: 0.1953326314687729
2023-10-03 20:02:42,645 - INFO - Epoch 67, Training Loss: 0.18782107532024384, Sample loss: 0.1972508281469345, Validation Loss: 0.23019129037857056
2023-10-03 20:02:46,404 - INFO - Epoch 68, Training Loss: 0.17785726487636566, Sample loss: 0.15183737874031067, Validation Loss: 0.18877993524074554
2023-10-03 20:02:50,088 - INFO - Epoch 69, Training Loss: 0.1965196579694748, Sample loss: 0.19858776032924652, Validation Loss: 0.24513711035251617
2023-10-03 20:02:53,635 - INFO - Epoch 70, Training Loss: 0.177284374833107, Sample loss: 0.19032230973243713, Validation Loss: 0.19539430737495422
2023-10-03 20:02:57,103 - INFO - Epoch 71, Training Loss: 0.17835329473018646, Sample loss: 0.20351529121398926, Validation Loss: 0.2295052409172058
2023-10-03 20:03:01,372 - INFO - Epoch 72, Training Loss: 0.18764175474643707, Sample loss: 0.21492914855480194, Validation Loss: 0.19524286687374115
2023-10-03 20:03:05,036 - INFO - Epoch 73, Training Loss: 0.1710219383239746, Sample loss: 0.17830446362495422, Validation Loss: 0.21582235395908356
2023-10-03 20:03:08,585 - INFO - Epoch 74, Training Loss: 0.1797059327363968, Sample loss: 0.13786494731903076, Validation Loss: 0.1978810429573059
2023-10-03 20:03:12,012 - INFO - Epoch 75, Training Loss: 0.16640286147594452, Sample loss: 0.16674520075321198, Validation Loss: 0.20809221267700195
2023-10-03 20:03:15,424 - INFO - Epoch 76, Training Loss: 0.18283630907535553, Sample loss: 0.17587171494960785, Validation Loss: 0.19965901970863342
2023-10-03 20:03:19,044 - INFO - Epoch 77, Training Loss: 0.16255788505077362, Sample loss: 0.1693061888217926, Validation Loss: 0.19321848452091217
2023-10-03 20:03:22,297 - INFO - Epoch 78, Training Loss: 0.1656399518251419, Sample loss: 0.1735970675945282, Validation Loss: 0.19701115787029266
2023-10-03 20:03:26,007 - INFO - Epoch 79, Training Loss: 0.17084556818008423, Sample loss: 0.16703879833221436, Validation Loss: 0.2009352743625641
2023-10-03 20:03:29,314 - INFO - Epoch 80, Training Loss: 0.1713564246892929, Sample loss: 0.17427822947502136, Validation Loss: 0.1951839178800583
2023-10-03 20:03:32,361 - INFO - Epoch 81, Training Loss: 0.16974395513534546, Sample loss: 0.15729154646396637, Validation Loss: 0.20695792138576508
2023-10-03 20:03:36,108 - INFO - Epoch 82, Training Loss: 0.17137490212917328, Sample loss: 0.16021716594696045, Validation Loss: 0.1952461451292038
2023-10-03 20:03:39,911 - INFO - Epoch 83, Training Loss: 0.16317154467105865, Sample loss: 0.14564239978790283, Validation Loss: 0.1956896185874939
2023-10-03 20:03:43,542 - INFO - Epoch 84, Training Loss: 0.1688598245382309, Sample loss: 0.1982497274875641, Validation Loss: 0.1927005648612976
2023-10-03 20:03:47,316 - INFO - Epoch 85, Training Loss: 0.15572099387645721, Sample loss: 0.1709417849779129, Validation Loss: 0.19612596929073334
2023-10-03 20:03:50,647 - INFO - Epoch 86, Training Loss: 0.17563119530677795, Sample loss: 0.15840572118759155, Validation Loss: 0.19810748100280762
2023-10-03 20:03:54,168 - INFO - Epoch 87, Training Loss: 0.15717492997646332, Sample loss: 0.15958461165428162, Validation Loss: 0.19699391722679138
2023-10-03 20:03:57,337 - INFO - Epoch 88, Training Loss: 0.17026109993457794, Sample loss: 0.16870492696762085, Validation Loss: 0.1900930255651474
2023-10-03 20:04:00,638 - INFO - Epoch 89, Training Loss: 0.162795752286911, Sample loss: 0.1508447229862213, Validation Loss: 0.2053646445274353
2023-10-03 20:04:04,044 - INFO - Epoch 90, Training Loss: 0.1805848777294159, Sample loss: 0.1668979972600937, Validation Loss: 0.1993655413389206
2023-10-03 20:04:07,348 - INFO - Epoch 91, Training Loss: 0.15679530799388885, Sample loss: 0.16082380712032318, Validation Loss: 0.20443099737167358
2023-10-03 20:04:10,393 - INFO - Epoch 92, Training Loss: 0.17514674365520477, Sample loss: 0.17114683985710144, Validation Loss: 0.19277605414390564
2023-10-03 20:04:14,230 - INFO - Epoch 93, Training Loss: 0.14641790091991425, Sample loss: 0.15123231709003448, Validation Loss: 0.188692107796669
2023-10-03 20:04:17,404 - INFO - Epoch 94, Training Loss: 0.1579902619123459, Sample loss: 0.14213593304157257, Validation Loss: 0.19391974806785583
2023-10-03 20:04:21,135 - INFO - Epoch 95, Training Loss: 0.14845408499240875, Sample loss: 0.15737657248973846, Validation Loss: 0.19447043538093567
2023-10-03 20:04:24,455 - INFO - Epoch 96, Training Loss: 0.18850554525852203, Sample loss: 0.20643964409828186, Validation Loss: 0.1978851854801178
2023-10-03 20:04:27,771 - INFO - Epoch 97, Training Loss: 0.14753811061382294, Sample loss: 0.13349780440330505, Validation Loss: 0.1907976269721985
2023-10-03 20:04:31,791 - INFO - Epoch 98, Training Loss: 0.17105510830879211, Sample loss: 0.18899419903755188, Validation Loss: 0.19352708756923676
2023-10-03 20:04:35,259 - INFO - Epoch 99, Training Loss: 0.15460769832134247, Sample loss: 0.16830025613307953, Validation Loss: 0.19948458671569824
2023-10-03 20:04:38,974 - INFO - Epoch 100, Training Loss: 0.16291627287864685, Sample loss: 0.18213045597076416, Validation Loss: 0.18319633603096008
2023-10-03 20:04:42,550 - INFO - Epoch 101, Training Loss: 0.15842893719673157, Sample loss: 0.16744288802146912, Validation Loss: 0.20953720808029175
2023-10-03 20:04:45,674 - INFO - Epoch 102, Training Loss: 0.1597641408443451, Sample loss: 0.1562245786190033, Validation Loss: 0.18004989624023438
2023-10-03 20:04:48,899 - INFO - Epoch 103, Training Loss: 0.16756056249141693, Sample loss: 0.19626523554325104, Validation Loss: 0.20648397505283356
2023-10-03 20:04:51,998 - INFO - Epoch 104, Training Loss: 0.15269997715950012, Sample loss: 0.14665956795215607, Validation Loss: 0.17813992500305176
2023-10-03 20:04:55,235 - INFO - Epoch 105, Training Loss: 0.16500574350357056, Sample loss: 0.1711193472146988, Validation Loss: 0.21303728222846985
2023-10-03 20:04:58,980 - INFO - Epoch 106, Training Loss: 0.15305785834789276, Sample loss: 0.1324562281370163, Validation Loss: 0.17634813487529755
2023-10-03 20:05:02,629 - INFO - Epoch 107, Training Loss: 0.16162416338920593, Sample loss: 0.15681754052639008, Validation Loss: 0.21304163336753845
2023-10-03 20:05:06,275 - INFO - Epoch 108, Training Loss: 0.14878703653812408, Sample loss: 0.13338029384613037, Validation Loss: 0.18121446669101715
2023-10-03 20:05:09,870 - INFO - Epoch 109, Training Loss: 0.1592211276292801, Sample loss: 0.15287582576274872, Validation Loss: 0.2139723300933838
2023-10-03 20:05:13,269 - INFO - Epoch 110, Training Loss: 0.15136845409870148, Sample loss: 0.15145911276340485, Validation Loss: 0.1818484216928482
2023-10-03 20:05:16,668 - INFO - Epoch 111, Training Loss: 0.15613876283168793, Sample loss: 0.16947586834430695, Validation Loss: 0.207724466919899
2023-10-03 20:05:20,215 - INFO - Epoch 112, Training Loss: 0.1488649845123291, Sample loss: 0.13920548558235168, Validation Loss: 0.17781378328800201
2023-10-03 20:05:23,669 - INFO - Epoch 113, Training Loss: 0.16010308265686035, Sample loss: 0.15936055779457092, Validation Loss: 0.22305864095687866
2023-10-03 20:05:27,149 - INFO - Epoch 114, Training Loss: 0.1579488068819046, Sample loss: 0.16211135685443878, Validation Loss: 0.17786084115505219
2023-10-03 20:05:30,354 - INFO - Epoch 115, Training Loss: 0.14476121962070465, Sample loss: 0.15897762775421143, Validation Loss: 0.2031378149986267
2023-10-03 20:05:34,418 - INFO - Epoch 116, Training Loss: 0.1614149510860443, Sample loss: 0.19048848748207092, Validation Loss: 0.18490435183048248
2023-10-03 20:05:37,789 - INFO - Epoch 117, Training Loss: 0.1455376297235489, Sample loss: 0.15253424644470215, Validation Loss: 0.20333674550056458
2023-10-03 20:05:40,787 - INFO - Epoch 118, Training Loss: 0.15349222719669342, Sample loss: 0.16147251427173615, Validation Loss: 0.17770221829414368
2023-10-03 20:05:43,986 - INFO - Epoch 119, Training Loss: 0.1547500044107437, Sample loss: 0.14447271823883057, Validation Loss: 0.2109590619802475
2023-10-03 20:05:47,405 - INFO - Epoch 120, Training Loss: 0.1468157023191452, Sample loss: 0.1568690538406372, Validation Loss: 0.1790168285369873
2023-10-03 20:05:50,626 - INFO - Epoch 121, Training Loss: 0.15870824456214905, Sample loss: 0.17411592602729797, Validation Loss: 0.21200042963027954
2023-10-03 20:05:54,118 - INFO - Epoch 122, Training Loss: 0.14576877653598785, Sample loss: 0.12449643760919571, Validation Loss: 0.17042215168476105
2023-10-03 20:05:57,545 - INFO - Epoch 123, Training Loss: 0.14750270545482635, Sample loss: 0.14952418208122253, Validation Loss: 0.21293386816978455
2023-10-03 20:06:01,132 - INFO - Epoch 124, Training Loss: 0.15274637937545776, Sample loss: 0.14240425825119019, Validation Loss: 0.17417261004447937
2023-10-03 20:06:04,529 - INFO - Epoch 125, Training Loss: 0.1363355666399002, Sample loss: 0.1308613419532776, Validation Loss: 0.20332585275173187
2023-10-03 20:06:08,223 - INFO - Epoch 126, Training Loss: 0.1557226926088333, Sample loss: 0.13770559430122375, Validation Loss: 0.17823170125484467
2023-10-03 20:06:11,613 - INFO - Epoch 127, Training Loss: 0.14290352165699005, Sample loss: 0.14908276498317719, Validation Loss: 0.20995958149433136
2023-10-03 20:06:15,318 - INFO - Epoch 128, Training Loss: 0.15133574604988098, Sample loss: 0.1611473262310028, Validation Loss: 0.1959751397371292
2023-10-03 20:06:18,971 - INFO - Epoch 129, Training Loss: 0.14701955020427704, Sample loss: 0.13456538319587708, Validation Loss: 0.2133936583995819
2023-10-03 20:06:22,622 - INFO - Epoch 130, Training Loss: 0.14841780066490173, Sample loss: 0.16088761389255524, Validation Loss: 0.19004887342453003
2023-10-03 20:06:25,956 - INFO - Epoch 131, Training Loss: 0.1490088254213333, Sample loss: 0.15489032864570618, Validation Loss: 0.21483875811100006
2023-10-03 20:06:29,483 - INFO - Epoch 132, Training Loss: 0.14608041942119598, Sample loss: 0.12559136748313904, Validation Loss: 0.1815468668937683
2023-10-03 20:06:32,897 - INFO - Epoch 133, Training Loss: 0.1463630497455597, Sample loss: 0.12827253341674805, Validation Loss: 0.2073328197002411
2023-10-03 20:06:36,297 - INFO - Epoch 134, Training Loss: 0.1552751213312149, Sample loss: 0.1575736105442047, Validation Loss: 0.19204752147197723
2023-10-03 20:06:39,734 - INFO - Epoch 135, Training Loss: 0.14490370452404022, Sample loss: 0.14561524987220764, Validation Loss: 0.2044677585363388
2023-10-03 20:06:43,340 - INFO - Epoch 136, Training Loss: 0.1462172418832779, Sample loss: 0.13906918466091156, Validation Loss: 0.18873046338558197
2023-10-03 20:06:46,668 - INFO - Epoch 137, Training Loss: 0.152125284075737, Sample loss: 0.16158905625343323, Validation Loss: 0.20849956572055817
2023-10-03 20:06:50,302 - INFO - Epoch 138, Training Loss: 0.14148148894309998, Sample loss: 0.12508052587509155, Validation Loss: 0.17885681986808777
2023-10-03 20:06:53,829 - INFO - Epoch 139, Training Loss: 0.15079627931118011, Sample loss: 0.13660036027431488, Validation Loss: 0.21031996607780457
2023-10-03 20:06:57,352 - INFO - Epoch 140, Training Loss: 0.14243581891059875, Sample loss: 0.13618497550487518, Validation Loss: 0.17590220272541046
2023-10-03 20:07:01,082 - INFO - Epoch 141, Training Loss: 0.19501037895679474, Sample loss: 0.20095911622047424, Validation Loss: 0.2402496039867401
2023-10-03 20:07:04,677 - INFO - Epoch 142, Training Loss: 0.12586833536624908, Sample loss: 0.14409048855304718, Validation Loss: 0.16316382586956024
2023-10-03 20:07:08,299 - INFO - Epoch 143, Training Loss: 0.16282221674919128, Sample loss: 0.1624564826488495, Validation Loss: 0.2390364110469818
2023-10-03 20:07:11,875 - INFO - Epoch 144, Training Loss: 0.1455889493227005, Sample loss: 0.18277248740196228, Validation Loss: 0.1812138706445694
2023-10-03 20:07:15,601 - INFO - Epoch 145, Training Loss: 0.13891395926475525, Sample loss: 0.13660050928592682, Validation Loss: 0.2078624814748764
2023-10-03 20:07:19,017 - INFO - Epoch 146, Training Loss: 0.15694235265254974, Sample loss: 0.13807609677314758, Validation Loss: 0.19534817337989807
2023-10-03 20:07:22,550 - INFO - Epoch 147, Training Loss: 0.14042024314403534, Sample loss: 0.13657492399215698, Validation Loss: 0.20053419470787048
2023-10-03 20:07:26,023 - INFO - Epoch 148, Training Loss: 0.14291934669017792, Sample loss: 0.14498372375965118, Validation Loss: 0.1860852986574173
2023-10-03 20:07:30,172 - INFO - Epoch 149, Training Loss: 0.15007831156253815, Sample loss: 0.15393875539302826, Validation Loss: 0.2235247790813446
2023-10-03 20:07:33,656 - INFO - Epoch 150, Training Loss: 0.13578100502490997, Sample loss: 0.14947855472564697, Validation Loss: 0.1815960556268692
2023-10-03 20:07:36,990 - INFO - Epoch 151, Training Loss: 0.14933863282203674, Sample loss: 0.15132567286491394, Validation Loss: 0.2172107696533203
2023-10-03 20:07:40,589 - INFO - Epoch 152, Training Loss: 0.13394828140735626, Sample loss: 0.13259892165660858, Validation Loss: 0.1732417792081833
2023-10-03 20:07:43,989 - INFO - Epoch 153, Training Loss: 0.14672526717185974, Sample loss: 0.14099811017513275, Validation Loss: 0.22421544790267944
2023-10-03 20:07:47,162 - INFO - Epoch 154, Training Loss: 0.14844924211502075, Sample loss: 0.15136687457561493, Validation Loss: 0.18699532747268677
2023-10-03 20:07:50,755 - INFO - Epoch 155, Training Loss: 0.13709229230880737, Sample loss: 0.14004287123680115, Validation Loss: 0.2063334584236145
2023-10-03 20:07:54,037 - INFO - Epoch 156, Training Loss: 0.14630921185016632, Sample loss: 0.13450929522514343, Validation Loss: 0.1926511824131012
2023-10-03 20:07:57,479 - INFO - Epoch 157, Training Loss: 0.14282378554344177, Sample loss: 0.13250654935836792, Validation Loss: 0.21029359102249146
2023-10-03 20:08:00,909 - INFO - Epoch 158, Training Loss: 0.14266161620616913, Sample loss: 0.13308049738407135, Validation Loss: 0.1905081570148468
2023-10-03 20:08:04,114 - INFO - Epoch 159, Training Loss: 0.1417742520570755, Sample loss: 0.15528015792369843, Validation Loss: 0.20403054356575012
2023-10-03 20:08:07,735 - INFO - Epoch 160, Training Loss: 0.13629849255084991, Sample loss: 0.14520663022994995, Validation Loss: 0.1871677041053772
2023-10-03 20:08:11,380 - INFO - Epoch 161, Training Loss: 0.14190977811813354, Sample loss: 0.13682948052883148, Validation Loss: 0.20180854201316833
2023-10-03 20:08:15,008 - INFO - Epoch 162, Training Loss: 0.13683481514453888, Sample loss: 0.1344342976808548, Validation Loss: 0.19568654894828796
2023-10-03 20:08:18,321 - INFO - Epoch 163, Training Loss: 0.1472243219614029, Sample loss: 0.15211570262908936, Validation Loss: 0.21860946714878082
2023-10-03 20:08:21,816 - INFO - Epoch 164, Training Loss: 0.1393754631280899, Sample loss: 0.14068052172660828, Validation Loss: 0.17982175946235657
2023-10-03 20:08:25,221 - INFO - Epoch 165, Training Loss: 0.14146845042705536, Sample loss: 0.12554116547107697, Validation Loss: 0.21681198477745056
2023-10-03 20:08:28,707 - INFO - Epoch 166, Training Loss: 0.13839752972126007, Sample loss: 0.15640516579151154, Validation Loss: 0.17943432927131653
2023-10-03 20:08:31,996 - INFO - Epoch 167, Training Loss: 0.1359039694070816, Sample loss: 0.1514042466878891, Validation Loss: 0.2119082659482956
2023-10-03 20:08:35,442 - INFO - Epoch 168, Training Loss: 0.14038434624671936, Sample loss: 0.14454856514930725, Validation Loss: 0.18663662672042847
2023-10-03 20:08:38,853 - INFO - Epoch 169, Training Loss: 0.1310928612947464, Sample loss: 0.14901214838027954, Validation Loss: 0.1986694186925888
2023-10-03 20:08:42,586 - INFO - Epoch 170, Training Loss: 0.13150691986083984, Sample loss: 0.13041554391384125, Validation Loss: 0.18508821725845337
2023-10-03 20:08:45,771 - INFO - Epoch 171, Training Loss: 0.1328970044851303, Sample loss: 0.13900037109851837, Validation Loss: 0.19747748970985413
2023-10-03 20:08:49,324 - INFO - Epoch 172, Training Loss: 0.13064217567443848, Sample loss: 0.1420031636953354, Validation Loss: 0.182266965508461
2023-10-03 20:08:52,767 - INFO - Epoch 173, Training Loss: 0.1334008276462555, Sample loss: 0.15096013247966766, Validation Loss: 0.20046688616275787
2023-10-03 20:08:56,093 - INFO - Epoch 174, Training Loss: 0.13001926243305206, Sample loss: 0.13134177029132843, Validation Loss: 0.1895245909690857
2023-10-03 20:08:59,450 - INFO - Epoch 175, Training Loss: 0.1399795562028885, Sample loss: 0.14435847103595734, Validation Loss: 0.19298450648784637
2023-10-03 20:09:02,738 - INFO - Epoch 176, Training Loss: 0.13175000250339508, Sample loss: 0.12448499351739883, Validation Loss: 0.19250963628292084
2023-10-03 20:09:06,016 - INFO - Epoch 177, Training Loss: 0.14309927821159363, Sample loss: 0.13600896298885345, Validation Loss: 0.20572508871555328
2023-10-03 20:09:09,460 - INFO - Epoch 178, Training Loss: 0.12410036474466324, Sample loss: 0.10722552239894867, Validation Loss: 0.1871672421693802
2023-10-03 20:09:12,747 - INFO - Epoch 179, Training Loss: 0.14477194845676422, Sample loss: 0.14001980423927307, Validation Loss: 0.19941161572933197
2023-10-03 20:09:16,544 - INFO - Epoch 180, Training Loss: 0.1342645287513733, Sample loss: 0.1317720115184784, Validation Loss: 0.19776397943496704
2023-10-03 20:09:20,011 - INFO - Epoch 181, Training Loss: 0.14818312227725983, Sample loss: 0.1568099558353424, Validation Loss: 0.19771496951580048
2023-10-03 20:09:23,428 - INFO - Epoch 182, Training Loss: 0.12673017382621765, Sample loss: 0.13224618136882782, Validation Loss: 0.18602418899536133
2023-10-03 20:09:27,099 - INFO - Epoch 183, Training Loss: 0.14735983312129974, Sample loss: 0.13293305039405823, Validation Loss: 0.1951185166835785
2023-10-03 20:09:30,502 - INFO - Epoch 184, Training Loss: 0.1214294284582138, Sample loss: 0.10849151760339737, Validation Loss: 0.19049963355064392
2023-10-03 20:09:33,891 - INFO - Epoch 185, Training Loss: 0.14671023190021515, Sample loss: 0.16777268052101135, Validation Loss: 0.19295981526374817
2023-10-03 20:09:37,184 - INFO - Epoch 186, Training Loss: 0.12064851820468903, Sample loss: 0.1251368671655655, Validation Loss: 0.19259849190711975
2023-10-03 20:09:40,431 - INFO - Epoch 187, Training Loss: 0.13693468272686005, Sample loss: 0.14683857560157776, Validation Loss: 0.19343438744544983
2023-10-03 20:09:43,928 - INFO - Epoch 188, Training Loss: 0.12941882014274597, Sample loss: 0.12163230031728745, Validation Loss: 0.19667106866836548
2023-10-03 20:09:47,608 - INFO - Epoch 189, Training Loss: 0.12997527420520782, Sample loss: 0.1342744529247284, Validation Loss: 0.1966920793056488
2023-10-03 20:09:51,041 - INFO - Epoch 190, Training Loss: 0.12555168569087982, Sample loss: 0.1292683184146881, Validation Loss: 0.18537822365760803
2023-10-03 20:09:54,376 - INFO - Epoch 191, Training Loss: 0.13510973751544952, Sample loss: 0.13981178402900696, Validation Loss: 0.1874525249004364
2023-10-03 20:09:57,728 - INFO - Epoch 192, Training Loss: 0.12547314167022705, Sample loss: 0.12616339325904846, Validation Loss: 0.20013095438480377
2023-10-03 20:10:01,520 - INFO - Epoch 193, Training Loss: 0.1420133113861084, Sample loss: 0.14891669154167175, Validation Loss: 0.19358693063259125
2023-10-03 20:10:05,008 - INFO - Epoch 194, Training Loss: 0.11929032951593399, Sample loss: 0.13536426424980164, Validation Loss: 0.17609232664108276
2023-10-03 20:10:08,581 - INFO - Epoch 195, Training Loss: 0.1452787071466446, Sample loss: 0.1332259327173233, Validation Loss: 0.20468099415302277
2023-10-03 20:10:11,889 - INFO - Epoch 196, Training Loss: 0.1298348605632782, Sample loss: 0.11904291808605194, Validation Loss: 0.1944827437400818
2023-10-03 20:10:15,927 - INFO - Epoch 197, Training Loss: 0.1271718293428421, Sample loss: 0.13511836528778076, Validation Loss: 0.19376009702682495
2023-10-03 20:10:19,287 - INFO - Epoch 198, Training Loss: 0.13195601105690002, Sample loss: 0.11689595878124237, Validation Loss: 0.19404572248458862
2023-10-03 20:10:22,911 - INFO - Epoch 199, Training Loss: 0.1229557991027832, Sample loss: 0.11094115674495697, Validation Loss: 0.19703800976276398
2023-10-03 20:10:26,327 - INFO - Epoch 200, Training Loss: 0.13642007112503052, Sample loss: 0.12756028771400452, Validation Loss: 0.208230122923851
2023-10-03 20:10:30,265 - INFO - Epoch 201, Training Loss: 0.12867245078086853, Sample loss: 0.12562692165374756, Validation Loss: 0.19329769909381866
2023-10-03 20:10:33,823 - INFO - Epoch 202, Training Loss: 0.13069528341293335, Sample loss: 0.1303676962852478, Validation Loss: 0.1917029470205307
2023-10-03 20:10:37,138 - INFO - Epoch 203, Training Loss: 0.13025693595409393, Sample loss: 0.13116386532783508, Validation Loss: 0.20124363899230957
2023-10-03 20:10:40,862 - INFO - Epoch 204, Training Loss: 0.12527020275592804, Sample loss: 0.13158544898033142, Validation Loss: 0.18005220592021942
2023-10-03 20:10:44,763 - INFO - Epoch 205, Training Loss: 0.12744580209255219, Sample loss: 0.1358218491077423, Validation Loss: 0.1984267234802246
2023-10-03 20:10:48,417 - INFO - Epoch 206, Training Loss: 0.12891003489494324, Sample loss: 0.13633586466312408, Validation Loss: 0.19349338114261627
2023-10-03 20:10:51,901 - INFO - Epoch 207, Training Loss: 0.12914645671844482, Sample loss: 0.11460952460765839, Validation Loss: 0.19278742372989655
2023-10-03 20:10:55,489 - INFO - Epoch 208, Training Loss: 0.13550201058387756, Sample loss: 0.14063717424869537, Validation Loss: 0.1976352035999298
2023-10-03 20:10:58,815 - INFO - Epoch 209, Training Loss: 0.12223920971155167, Sample loss: 0.13228759169578552, Validation Loss: 0.1907501071691513
2023-10-03 20:11:02,091 - INFO - Epoch 210, Training Loss: 0.13886456191539764, Sample loss: 0.14032281935214996, Validation Loss: 0.20561766624450684
2023-10-03 20:11:05,612 - INFO - Epoch 211, Training Loss: 0.12477146834135056, Sample loss: 0.12827220559120178, Validation Loss: 0.19385084509849548
2023-10-03 20:11:09,165 - INFO - Epoch 212, Training Loss: 0.13829351961612701, Sample loss: 0.1405520737171173, Validation Loss: 0.19677624106407166
2023-10-03 20:11:12,564 - INFO - Epoch 213, Training Loss: 0.11812031269073486, Sample loss: 0.1276675909757614, Validation Loss: 0.18650668859481812
2023-10-03 20:11:16,270 - INFO - Epoch 214, Training Loss: 0.14140181243419647, Sample loss: 0.13676033914089203, Validation Loss: 0.21772180497646332
2023-10-03 20:11:19,753 - INFO - Epoch 215, Training Loss: 0.11054374277591705, Sample loss: 0.122770294547081, Validation Loss: 0.18329010903835297
2023-10-03 20:11:23,383 - INFO - Epoch 216, Training Loss: 0.15080401301383972, Sample loss: 0.1470528244972229, Validation Loss: 0.2026815116405487
2023-10-03 20:11:26,750 - INFO - Epoch 217, Training Loss: 0.11427182704210281, Sample loss: 0.11883215606212616, Validation Loss: 0.192332923412323
2023-10-03 20:11:30,577 - INFO - Epoch 218, Training Loss: 0.1364578753709793, Sample loss: 0.11883749067783356, Validation Loss: 0.1934930682182312
2023-10-03 20:11:34,411 - INFO - Epoch 219, Training Loss: 0.11865221709012985, Sample loss: 0.13422107696533203, Validation Loss: 0.1994026005268097
2023-10-03 20:11:38,045 - INFO - Epoch 220, Training Loss: 0.13434022665023804, Sample loss: 0.15228450298309326, Validation Loss: 0.18836753070354462
2023-10-03 20:11:41,808 - INFO - Epoch 221, Training Loss: 0.11595452576875687, Sample loss: 0.11968225240707397, Validation Loss: 0.2103252410888672
2023-10-03 20:11:45,632 - INFO - Epoch 222, Training Loss: 0.14826081693172455, Sample loss: 0.12999652326107025, Validation Loss: 0.19901308417320251
2023-10-03 20:11:49,272 - INFO - Epoch 223, Training Loss: 0.11016486585140228, Sample loss: 0.1273995339870453, Validation Loss: 0.1914009004831314
2023-10-03 20:11:52,580 - INFO - Epoch 224, Training Loss: 0.1502712070941925, Sample loss: 0.18679824471473694, Validation Loss: 0.19949056208133698
2023-10-03 20:11:55,968 - INFO - Epoch 225, Training Loss: 0.11195840686559677, Sample loss: 0.11480338871479034, Validation Loss: 0.1994931548833847
2023-10-03 20:11:59,549 - INFO - Epoch 226, Training Loss: 0.13353678584098816, Sample loss: 0.16482463479042053, Validation Loss: 0.18667937815189362
2023-10-03 20:12:02,970 - INFO - Epoch 227, Training Loss: 0.11446037888526917, Sample loss: 0.10669995844364166, Validation Loss: 0.19911034405231476
2023-10-03 20:12:06,616 - INFO - Epoch 228, Training Loss: 0.12839169800281525, Sample loss: 0.11042334884405136, Validation Loss: 0.18294842541217804
2023-10-03 20:12:10,454 - INFO - Epoch 229, Training Loss: 0.12510721385478973, Sample loss: 0.11124453693628311, Validation Loss: 0.21365366876125336
2023-10-03 20:12:14,475 - INFO - Epoch 230, Training Loss: 0.12337096035480499, Sample loss: 0.11614252626895905, Validation Loss: 0.1820734441280365
2023-10-03 20:12:18,467 - INFO - Epoch 231, Training Loss: 0.12111257016658783, Sample loss: 0.13021162152290344, Validation Loss: 0.208883598446846
2023-10-03 20:12:22,173 - INFO - Epoch 232, Training Loss: 0.12299999594688416, Sample loss: 0.11516579240560532, Validation Loss: 0.18089617788791656
2023-10-03 20:12:25,928 - INFO - Epoch 233, Training Loss: 0.12064551562070847, Sample loss: 0.12283984571695328, Validation Loss: 0.21096712350845337
2023-10-03 20:12:29,720 - INFO - Epoch 234, Training Loss: 0.12642566859722137, Sample loss: 0.11938424408435822, Validation Loss: 0.18214569985866547
2023-10-03 20:12:33,385 - INFO - Epoch 235, Training Loss: 0.12513932585716248, Sample loss: 0.1331918090581894, Validation Loss: 0.20506352186203003
2023-10-03 20:12:36,991 - INFO - Epoch 236, Training Loss: 0.11861836910247803, Sample loss: 0.10899876058101654, Validation Loss: 0.18023601174354553
2023-10-03 20:12:40,529 - INFO - Epoch 237, Training Loss: 0.12109572440385818, Sample loss: 0.13480930030345917, Validation Loss: 0.19985954463481903
2023-10-03 20:12:44,463 - INFO - Epoch 238, Training Loss: 0.12915833294391632, Sample loss: 0.11273107677698135, Validation Loss: 0.2012852281332016
2023-10-03 20:12:47,845 - INFO - Epoch 239, Training Loss: 0.11183977127075195, Sample loss: 0.11729631572961807, Validation Loss: 0.18747347593307495
2023-10-03 20:12:51,245 - INFO - Epoch 240, Training Loss: 0.1261085867881775, Sample loss: 0.12555763125419617, Validation Loss: 0.19055794179439545
2023-10-03 20:12:54,654 - INFO - Epoch 241, Training Loss: 0.12183675169944763, Sample loss: 0.13702832162380219, Validation Loss: 0.20053456723690033
2023-10-03 20:12:58,465 - INFO - Epoch 242, Training Loss: 0.11998866498470306, Sample loss: 0.14122232794761658, Validation Loss: 0.18522265553474426
2023-10-03 20:13:02,040 - INFO - Epoch 243, Training Loss: 0.11887405812740326, Sample loss: 0.11963455379009247, Validation Loss: 0.20380036532878876
2023-10-03 20:13:05,640 - INFO - Epoch 244, Training Loss: 0.13370384275913239, Sample loss: 0.13425585627555847, Validation Loss: 0.19363798201084137
2023-10-03 20:13:09,266 - INFO - Epoch 245, Training Loss: 0.10975582897663116, Sample loss: 0.11075528711080551, Validation Loss: 0.1874241828918457
2023-10-03 20:13:12,861 - INFO - Epoch 246, Training Loss: 0.12485601007938385, Sample loss: 0.11648605763912201, Validation Loss: 0.2016485631465912
2023-10-03 20:13:16,652 - INFO - Epoch 247, Training Loss: 0.11646448820829391, Sample loss: 0.13853372633457184, Validation Loss: 0.19273480772972107
2023-10-03 20:13:20,112 - INFO - Epoch 248, Training Loss: 0.11844829469919205, Sample loss: 0.11413991451263428, Validation Loss: 0.1842266172170639
2023-10-03 20:13:23,645 - INFO - Epoch 249, Training Loss: 0.11849445849657059, Sample loss: 0.1162881851196289, Validation Loss: 0.20449210703372955
2023-10-03 20:13:27,190 - INFO - Epoch 250, Training Loss: 0.11915465444326401, Sample loss: 0.11819081008434296, Validation Loss: 0.196693554520607
2023-10-03 20:13:30,895 - INFO - Epoch 251, Training Loss: 0.11848071217536926, Sample loss: 0.13758721947669983, Validation Loss: 0.18446952104568481
2023-10-03 20:13:34,682 - INFO - Epoch 252, Training Loss: 0.12400195002555847, Sample loss: 0.1393144428730011, Validation Loss: 0.21202905476093292
2023-10-03 20:13:38,052 - INFO - Epoch 253, Training Loss: 0.1289968341588974, Sample loss: 0.1351681649684906, Validation Loss: 0.20276539027690887
2023-10-03 20:13:41,657 - INFO - Epoch 254, Training Loss: 0.11445677280426025, Sample loss: 0.10529832541942596, Validation Loss: 0.19287720322608948
2023-10-03 20:13:45,006 - INFO - Epoch 255, Training Loss: 0.1433221846818924, Sample loss: 0.15385815501213074, Validation Loss: 0.22169767320156097
2023-10-03 20:13:48,547 - INFO - Epoch 256, Training Loss: 0.11065144836902618, Sample loss: 0.12705661356449127, Validation Loss: 0.1825198084115982
2023-10-03 20:13:51,794 - INFO - Epoch 257, Training Loss: 0.1179535910487175, Sample loss: 0.12490998208522797, Validation Loss: 0.1861526221036911
2023-10-03 20:13:55,325 - INFO - Epoch 258, Training Loss: 0.11434086412191391, Sample loss: 0.12278975546360016, Validation Loss: 0.20133352279663086
2023-10-03 20:13:58,728 - INFO - Epoch 259, Training Loss: 0.1192210242152214, Sample loss: 0.12486495822668076, Validation Loss: 0.1838466078042984
2023-10-03 20:14:02,173 - INFO - Epoch 260, Training Loss: 0.11714901775121689, Sample loss: 0.11473117023706436, Validation Loss: 0.20267273485660553
2023-10-03 20:14:05,877 - INFO - Epoch 261, Training Loss: 0.12128124386072159, Sample loss: 0.12102918326854706, Validation Loss: 0.19707205891609192
2023-10-03 20:14:09,861 - INFO - Epoch 262, Training Loss: 0.11774377524852753, Sample loss: 0.1125817745923996, Validation Loss: 0.19740986824035645
2023-10-03 20:14:13,480 - INFO - Epoch 263, Training Loss: 0.11716686189174652, Sample loss: 0.11951231956481934, Validation Loss: 0.19601556658744812
2023-10-03 20:14:16,710 - INFO - Epoch 264, Training Loss: 0.1169847622513771, Sample loss: 0.13057273626327515, Validation Loss: 0.191086545586586
2023-10-03 20:14:20,100 - INFO - Epoch 265, Training Loss: 0.11342276632785797, Sample loss: 0.12443487346172333, Validation Loss: 0.18864859640598297
2023-10-03 20:14:23,751 - INFO - Epoch 266, Training Loss: 0.12134658545255661, Sample loss: 0.12610703706741333, Validation Loss: 0.1886027455329895
2023-10-03 20:14:27,338 - INFO - Epoch 267, Training Loss: 0.10868731886148453, Sample loss: 0.11686732620000839, Validation Loss: 0.19519096612930298
2023-10-03 20:14:30,712 - INFO - Epoch 268, Training Loss: 0.12838530540466309, Sample loss: 0.13202419877052307, Validation Loss: 0.20887207984924316
2023-10-03 20:14:34,541 - INFO - Epoch 269, Training Loss: 0.11051622033119202, Sample loss: 0.10984523594379425, Validation Loss: 0.20091141760349274
2023-10-03 20:14:37,861 - INFO - Epoch 270, Training Loss: 0.11991090327501297, Sample loss: 0.12280137836933136, Validation Loss: 0.18750986456871033
2023-10-03 20:14:41,297 - INFO - Epoch 271, Training Loss: 0.12180270254611969, Sample loss: 0.12196320295333862, Validation Loss: 0.20963777601718903
2023-10-03 20:14:45,058 - INFO - Epoch 272, Training Loss: 0.11220826953649521, Sample loss: 0.1204693540930748, Validation Loss: 0.18584966659545898
2023-10-03 20:14:48,641 - INFO - Epoch 273, Training Loss: 0.12097534537315369, Sample loss: 0.11532387882471085, Validation Loss: 0.19971102476119995
2023-10-03 20:14:52,572 - INFO - Epoch 274, Training Loss: 0.11298438161611557, Sample loss: 0.11805412918329239, Validation Loss: 0.18535441160202026
2023-10-03 20:14:56,303 - INFO - Epoch 275, Training Loss: 0.11745541542768478, Sample loss: 0.11793661117553711, Validation Loss: 0.19951319694519043
2023-10-03 20:15:00,068 - INFO - Epoch 276, Training Loss: 0.11579878628253937, Sample loss: 0.1094045415520668, Validation Loss: 0.1915382593870163
2023-10-03 20:15:03,757 - INFO - Epoch 277, Training Loss: 0.1159297376871109, Sample loss: 0.11464613676071167, Validation Loss: 0.19140560925006866
2023-10-03 20:15:07,825 - INFO - Epoch 278, Training Loss: 0.11191888153553009, Sample loss: 0.11498355865478516, Validation Loss: 0.19563373923301697
2023-10-03 20:15:11,575 - INFO - Epoch 279, Training Loss: 0.1181814968585968, Sample loss: 0.1273413896560669, Validation Loss: 0.19190876185894012
2023-10-03 20:15:15,183 - INFO - Epoch 280, Training Loss: 0.10656954348087311, Sample loss: 0.1141684278845787, Validation Loss: 0.20191223919391632
2023-10-03 20:15:18,963 - INFO - Epoch 281, Training Loss: 0.12108643352985382, Sample loss: 0.12821048498153687, Validation Loss: 0.19401255249977112
2023-10-03 20:15:22,430 - INFO - Epoch 282, Training Loss: 0.11437065899372101, Sample loss: 0.119373619556427, Validation Loss: 0.19479252398014069
2023-10-03 20:15:25,909 - INFO - Epoch 283, Training Loss: 0.10821247845888138, Sample loss: 0.09845565259456635, Validation Loss: 0.18497096002101898
2023-10-03 20:15:29,683 - INFO - Epoch 284, Training Loss: 0.12119702249765396, Sample loss: 0.11971087753772736, Validation Loss: 0.20578190684318542
2023-10-03 20:15:33,246 - INFO - Epoch 285, Training Loss: 0.11756423115730286, Sample loss: 0.11800479888916016, Validation Loss: 0.1802600920200348
2023-10-03 20:15:36,954 - INFO - Epoch 286, Training Loss: 0.11867216229438782, Sample loss: 0.12391272932291031, Validation Loss: 0.19662140309810638
2023-10-03 20:15:41,098 - INFO - Epoch 287, Training Loss: 0.11729240417480469, Sample loss: 0.11267860233783722, Validation Loss: 0.18618105351924896
2023-10-03 20:15:44,473 - INFO - Epoch 288, Training Loss: 0.11184147000312805, Sample loss: 0.10524076223373413, Validation Loss: 0.19874991476535797
2023-10-03 20:15:48,021 - INFO - Epoch 289, Training Loss: 0.11912981420755386, Sample loss: 0.12821994721889496, Validation Loss: 0.1892559826374054
2023-10-03 20:15:51,569 - INFO - Epoch 290, Training Loss: 0.10638553649187088, Sample loss: 0.10630655288696289, Validation Loss: 0.1906035989522934
2023-10-03 20:15:55,096 - INFO - Epoch 291, Training Loss: 0.11187785118818283, Sample loss: 0.11320251226425171, Validation Loss: 0.1940223127603531
2023-10-03 20:15:58,348 - INFO - Epoch 292, Training Loss: 0.11299221217632294, Sample loss: 0.12266077846288681, Validation Loss: 0.19022919237613678
2023-10-03 20:16:02,292 - INFO - Epoch 293, Training Loss: 0.11345011740922928, Sample loss: 0.11920900642871857, Validation Loss: 0.1908532977104187
2023-10-03 20:16:05,789 - INFO - Epoch 294, Training Loss: 0.12216909974813461, Sample loss: 0.13557873666286469, Validation Loss: 0.20194481313228607
2023-10-03 20:16:09,632 - INFO - Epoch 295, Training Loss: 0.11012507975101471, Sample loss: 0.11202029138803482, Validation Loss: 0.19560550153255463
2023-10-03 20:16:13,129 - INFO - Epoch 296, Training Loss: 0.11514222621917725, Sample loss: 0.10434635728597641, Validation Loss: 0.18711057305335999
2023-10-03 20:16:17,217 - INFO - Epoch 297, Training Loss: 0.11313071101903915, Sample loss: 0.10583259165287018, Validation Loss: 0.20172163844108582
2023-10-03 20:16:20,541 - INFO - Epoch 298, Training Loss: 0.1113835796713829, Sample loss: 0.11974843591451645, Validation Loss: 0.18715275824069977
2023-10-03 20:16:23,999 - INFO - Epoch 299, Training Loss: 0.11553610116243362, Sample loss: 0.11211945116519928, Validation Loss: 0.211747944355011

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import time\n",
    "import logging\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ww = torch.load('/scratch/bs4283/visual_autolabel/best_func.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "def convrelu(in_channels, out_channels,\n",
    "             kernel=3, padding=None, stride=1, bias=True, inplace=True):\n",
    "    \"\"\"Shortcut for creating a PyTorch 2D convolution followed by a ReLU.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        The number of input channels in the convolution.\n",
    "    out_channels : int\n",
    "        The number of output channels in the convolution.\n",
    "    kernel : int, optional\n",
    "        The kernel size for the convolution (default: 3).\n",
    "    padding : int or None, optional\n",
    "        The padding size for the convolution; if `None` (the default), then\n",
    "        chooses a padding size that attempts to maintain the image-size.\n",
    "    stride : int, optional\n",
    "        The stride to use in the convolution (default: 1).\n",
    "    bias : boolean, optional\n",
    "        Whether the convolution has a learnable bias (default: True).\n",
    "    inplace : boolean, optional\n",
    "        Whether to perform the ReLU operation in-place (default: True).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.nn.Sequential\n",
    "        The model of a 2D-convolution followed by a ReLU operation.\n",
    "    \"\"\"\n",
    "#    if padding is None:\n",
    "#        padding = kernel_default_padding(kernel)\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(in_channels, out_channels, kernel,\n",
    "                        padding=padding, bias=bias),\n",
    "        torch.nn.ReLU(inplace=inplace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    \"\"\"a U-Net with a ResNet18 backbone for learning visual area labels.\n",
    "\n",
    "    The `UNet` class implements a [\"U-Net\"](https://arxiv.org/abs/1505.04597)\n",
    "    with a [ResNet-18](https://pytorch.org/hub/pytorch_vision_resnet/) bacbone.\n",
    "    The class inherits from `torch.nn.Module`.\n",
    "    \n",
    "    The original implementation of this class was by Shaoling Chen\n",
    "    (sc6995@nyu.edu), and additional modifications have been made by Noah C.\n",
    "    Benson (nben@uw.edu).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_count : int\n",
    "        The number of channels (features) in the input image. When using an\n",
    "        `HCPVisualDataset` object for training, this value should be set to 4\n",
    "        if the dataset uses the `'anat'` or `'func'` features and 8 if it uses\n",
    "        the `'both'` features.\n",
    "    segment_count : int\n",
    "        The number of segments (AKA classes, labels) in the output data. For\n",
    "        V1-V3 this is typically either 3 (V1, V2, V3) or 6 (LV1, LV2, LV3, RV1,\n",
    "        RV2, RV3).\n",
    "    base_model : model name or tuple, optional\n",
    "        The name of the model that is to be used as the base/backbone of the\n",
    "        UNet. The default is `'resnet18'`, but \n",
    "    pretrained : boolean, optional\n",
    "        Whether to use a pretrained base model for the backbone (`True`) or not\n",
    "        (`False`). The default is `False`.\n",
    "    logits : boolean, optional\n",
    "        Whether the model should return logits (`True`) or probabilities\n",
    "        (`False`). The default is `True`.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    pretrained_base : boolean\n",
    "        `True` if the base model used in this `UNet` was originally pre-trained\n",
    "        and `False` otherwise.\n",
    "    base_model : PyTorch Module\n",
    "        The ResNet-18 model that is used as the backbone of the `UNet` model.\n",
    "    base_layers : list of PyTorch Modules\n",
    "        The ResNet-18 layers that are used in the backbone of the `UNet` model.\n",
    "    feature_count : int\n",
    "        The number of input channels (features) that the model expects in input\n",
    "        images.\n",
    "    segment_count : int\n",
    "        The number of segments (labels) predicted by the model.\n",
    "    logits : bool\n",
    "        `True` if the output of the model is in logits and `False` if its output\n",
    "        is in probabilities.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_count, segment_count,\n",
    "                 base_model='resnet18',\n",
    "                 pretrained=False,\n",
    "                 logits=False):\n",
    "        import torch.nn as nn\n",
    "        # Initialize the super-class.\n",
    "        super().__init__()\n",
    "        # Store some basic attributes.\n",
    "        self.feature_count = feature_count\n",
    "        self.segment_count = segment_count\n",
    "        self.pretrained = pretrained\n",
    "        self.logits = logits\n",
    "        # Set up the base model and base layers for the model.\n",
    "        if pretrained:\n",
    "            weights = 'IMAGENET1K_V1'\n",
    "        else:\n",
    "            weights = None\n",
    "        import torchvision.models as mdls\n",
    "        base_model = getattr(mdls, base_model)\n",
    "        try:\n",
    "            base_model = base_model(weights=weights,\n",
    "                                    num_classes=segment_count)\n",
    "        except TypeError:\n",
    "            base_model = base_model(pretrained=pretrained,\n",
    "                                    num_classes=segment_count)\n",
    "        # Not sure we should store the base model; seems like a good idea, but\n",
    "        # does it get caught up in PyTorch's Module data when we do?\n",
    "        #self.base_model = resnet18(pretrained=pretrained)\n",
    "        # Because the input size may not be 3 and the output size may not be 3,\n",
    "        # we want to add an additional \n",
    "        if feature_count != 3:\n",
    "            # Adjust the first convolution's number of input channels.\n",
    "            c1 = base_model.conv1\n",
    "            base_model.conv1 = nn.Conv2d(\n",
    "                feature_count, c1.out_channels,\n",
    "                kernel_size=c1.kernel_size, stride=c1.stride,\n",
    "                padding=c1.padding, bias=c1.bias)\n",
    "        base_layers = list(base_model.children())\n",
    "        #self.base_layers = base_layers\n",
    "        # Make the U-Net layers out of the base-layers.\n",
    "        # size = (N, 64, H/2, W/2)\n",
    "        self.layer0 = nn.Sequential(*base_layers[:3]) \n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        # size = (N, 64, H/4, W/4)\n",
    "        self.layer1 = nn.Sequential(*base_layers[3:5])\n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
    "        # size = (N, 128, H/8, W/8)        \n",
    "        self.layer2 = base_layers[5]\n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)  \n",
    "        # size = (N, 256, H/16, W/16)\n",
    "        self.layer3 = base_layers[6]  \n",
    "        self.layer3_1x1 = convrelu(256, 256, 1, 0)  \n",
    "        # size = (N, 512, H/32, W/32)\n",
    "        self.layer4 = base_layers[7]\n",
    "        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
    "        # The up-swing of the UNet; we will need to upsample the image.\n",
    "        self.upsample = nn.Upsample(scale_factor=2,\n",
    "                                    mode='bilinear',\n",
    "                                    align_corners=True)\n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "        self.conv_original_size0 = convrelu(feature_count, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        self.conv_last = nn.Conv2d(64, segment_count, 1)\n",
    "    def forward(self, input):\n",
    "        # Do the original size convolutions.\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "        # Now the front few layers, which we save for adding back in on the UNet\n",
    "        # up-swing below.\n",
    "        layer0 = self.layer0(input)\n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        # Now, we start the up-swing; each step must upsample the image.\n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        # Up-swing Step 1\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    "        # Up-swing Step 2\n",
    "        x = self.upsample(x)\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "        # Up-swing Step 3\n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "        # Up-swing Step 4\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "        # Up-swing Step 5\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)        \n",
    "        # And the final convolution.\n",
    "        out = self.conv_last(x)\n",
    "        if not self.logits:\n",
    "            out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unet  = UNet(feature_count = 11, segment_count = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "model_unet.layer0[0].weight = nn.Parameter(model_ww['layer0.0.weight'],requires_grad=True)\n",
    "model_unet.layer0[1].weight = nn.Parameter(model_ww['layer0.1.weight'],requires_grad=True)\n",
    "model_unet.layer0[1].bias = nn.Parameter(model_ww['layer0.1.bias'],requires_grad=True)\n",
    "model_unet.layer0[1].running_mean = nn.Parameter(model_ww['layer0.1.running_mean'],requires_grad=False)\n",
    "model_unet.layer0[1].running_var = nn.Parameter(model_ww['layer0.1.running_var'],requires_grad=False)\n",
    "model_unet.layer0[1].num_batches_tracked = nn.Parameter(model_ww['layer0.1.num_batches_tracked'],requires_grad=False)\n",
    "model_unet.layer0_1x1[0].weight = nn.Parameter(model_ww['layer0_1x1.0.weight'],requires_grad=True)\n",
    "model_unet.layer0_1x1[0].bias = nn.Parameter(model_ww['layer0_1x1.0.bias'],requires_grad=True)\n",
    "model_unet.layer1[1][0].conv1.weight = nn.Parameter(model_ww['layer1.1.0.conv1.weight'],requires_grad=True)\n",
    "model_unet.layer1[1][0].bn1.weight = nn.Parameter(model_ww['layer1.1.0.bn1.weight'],requires_grad=True)\n",
    "model_unet.layer1[1][0].bn1.bias = nn.Parameter(model_ww['layer1.1.0.bn1.bias'],requires_grad=True)\n",
    "model_unet.layer1[1][0].bn1.running_mean = nn.Parameter(model_ww['layer1.1.0.bn1.running_mean'],requires_grad=False)\n",
    "model_unet.layer1[1][0].bn1.running_var = nn.Parameter(model_ww['layer1.1.0.bn1.running_var'],requires_grad=False)\n",
    "model_unet.layer1[1][0].bn1.num_batches_tracked = nn.Parameter(model_ww['layer1.1.0.bn1.num_batches_tracked'],requires_grad=False)\n",
    "model_unet.layer1[1][0].conv2.weight = nn.Parameter(model_ww['layer1.1.0.conv2.weight'],requires_grad=True)\n",
    "model_unet.layer1[1][0].bn2.weight = nn.Parameter(model_ww['layer1.1.0.bn2.weight'],requires_grad=True)\n",
    "\n",
    "\n",
    "\n",
    "model_unet.layer1[1][0].bn2.bias = nn.Parameter(model_ww['layer1.1.0.bn2.bias'],requires_grad=True)\n",
    "model_unet.layer1[1][0].bn2.running_mean = nn.Parameter(model_ww['layer1.1.0.bn2.running_mean'],requires_grad=False)\n",
    "model_unet.layer1[1][0].bn2.running_var = nn.Parameter(model_ww['layer1.1.0.bn2.running_var'],requires_grad=False)\n",
    "model_unet.layer1[1][0].bn2.num_batches_tracked = nn.Parameter(model_ww['layer1.1.0.bn2.num_batches_tracked'],requires_grad=False)\n",
    "\n",
    "\n",
    "model_unet.layer1[1][1].conv1.weight = nn.Parameter(model_ww['layer1.1.1.conv1.weight'],requires_grad=True)\n",
    "model_unet.layer1[1][1].bn1.weight = nn.Parameter(model_ww['layer1.1.1.bn1.weight'],requires_grad=True)\n",
    "model_unet.layer1[1][1].bn1.bias = nn.Parameter(model_ww['layer1.1.1.bn1.bias'],requires_grad=True)\n",
    "model_unet.layer1[1][1].bn1.running_mean = nn.Parameter(model_ww['layer1.1.1.bn1.running_mean'],requires_grad=False)\n",
    "model_unet.layer1[1][1].bn1.running_var = nn.Parameter(model_ww['layer1.1.1.bn1.running_var'],requires_grad=False)\n",
    "model_unet.layer1[1][1].bn1.num_batches_tracked = nn.Parameter(model_ww['layer1.1.1.bn1.num_batches_tracked'],requires_grad=False)\n",
    "\n",
    "\n",
    "model_unet.layer1[1][1].conv2.weight = nn.Parameter(model_ww['layer1.1.1.conv2.weight'],requires_grad=True)\n",
    "model_unet.layer1[1][1].bn2.weight = nn.Parameter(model_ww['layer1.1.1.bn2.weight'],requires_grad=True)\n",
    "model_unet.layer1[1][1].bn2.bias = nn.Parameter(model_ww['layer1.1.1.bn2.bias'],requires_grad=True)\n",
    "model_unet.layer1[1][1].bn2.running_mean = nn.Parameter(model_ww['layer1.1.1.bn2.running_mean'],requires_grad=False)\n",
    "model_unet.layer1[1][1].bn2.running_var = nn.Parameter(model_ww['layer1.1.1.bn2.running_var'],requires_grad=False)\n",
    "model_unet.layer1[1][1].bn2.num_batches_tracked = nn.Parameter(model_ww['layer1.1.1.bn2.num_batches_tracked'],requires_grad=False)\n",
    "\n",
    "model_unet.layer1_1x1[0].weight = nn.Parameter(model_ww['layer1_1x1.0.weight'],requires_grad=True)\n",
    "model_unet.layer1_1x1[0].bias = nn.Parameter(model_ww['layer1_1x1.0.bias'],requires_grad=True)\n",
    "\n",
    "model_unet.layer2[0].conv1.weight = nn.Parameter(model_ww['layer2.0.conv1.weight'],requires_grad=True)\n",
    "model_unet.layer2[0].bn1.weight = nn.Parameter(model_ww['layer2.0.bn1.weight'],requires_grad=True)\n",
    "model_unet.layer2[0].bn1.bias = nn.Parameter(model_ww['layer2.0.bn1.bias'],requires_grad=True)\n",
    "model_unet.layer2[0].bn1.running_mean = nn.Parameter(model_ww['layer2.0.bn1.running_mean'],requires_grad=False)\n",
    "model_unet.layer2[0].bn1.running_var = nn.Parameter(model_ww['layer2.0.bn1.running_var'],requires_grad=False)\n",
    "model_unet.layer2[0].bn1.num_batches_tracked = nn.Parameter(model_ww['layer2.0.bn1.num_batches_tracked'],requires_grad=False)\n",
    "model_unet.layer2[0].conv2.weight = nn.Parameter(model_ww['layer2.0.conv2.weight'],requires_grad=True)\n",
    "model_unet.layer2[0].bn2.weight = nn.Parameter(model_ww['layer2.0.bn2.weight'],requires_grad=True)\n",
    "model_unet.layer2[0].bn2.bias = nn.Parameter(model_ww['layer2.0.bn2.bias'],requires_grad=True)\n",
    "model_unet.layer2[0].bn2.running_mean = nn.Parameter(model_ww['layer2.0.bn2.running_mean'],requires_grad=False)\n",
    "model_unet.layer2[0].bn2.running_var = nn.Parameter(model_ww['layer2.0.bn2.running_var'],requires_grad=False)\n",
    "model_unet.layer2[0].bn2.num_batches_tracked = nn.Parameter(model_ww['layer2.0.bn2.num_batches_tracked'],requires_grad=False)\n",
    "\n",
    "model_unet.layer2[0].downsample[0].weight = nn.Parameter(model_ww['layer2.0.downsample.0.weight'],requires_grad=True)\n",
    "model_unet.layer2[0].downsample[1].weight = nn.Parameter(model_ww['layer2.0.downsample.1.weight'],requires_grad=True)\n",
    "model_unet.layer2[0].downsample[1].bias = nn.Parameter(model_ww[ 'layer2.0.downsample.1.bias'],requires_grad=True)\n",
    "model_unet.layer2[0].downsample[1].running_mean = nn.Parameter(model_ww['layer2.0.downsample.1.running_mean'],requires_grad=False)\n",
    "model_unet.layer2[0].downsample[1].running_var = nn.Parameter(model_ww['layer2.0.downsample.1.running_var'],requires_grad=False)\n",
    "model_unet.layer2[0].downsample[1].num_batches_tracked = nn.Parameter(model_ww['layer2.0.downsample.1.num_batches_tracked'],requires_grad=False)\n",
    "\n",
    "\n",
    "model_unet.layer2[1].conv1.weight = nn.Parameter(model_ww['layer2.1.conv1.weight'],requires_grad=True)\n",
    "model_unet.layer2[1].bn1.weight = nn.Parameter(model_ww['layer2.1.bn1.weight'],requires_grad=True)\n",
    "model_unet.layer2[1].bn1.bias = nn.Parameter(model_ww['layer2.1.bn1.bias'],requires_grad=True)\n",
    "model_unet.layer2[1].bn1.running_mean = nn.Parameter(model_ww['layer2.1.bn1.running_mean'],requires_grad=False)\n",
    "model_unet.layer2[1].bn1.running_var = nn.Parameter(model_ww['layer2.1.bn1.running_var'],requires_grad=False)\n",
    "model_unet.layer2[1].bn1.num_batches_tracked = nn.Parameter(model_ww['layer2.1.bn1.num_batches_tracked'],requires_grad=False)\n",
    "model_unet.layer2[1].conv2.weight = nn.Parameter(model_ww['layer2.1.conv2.weight'],requires_grad=True)\n",
    "model_unet.layer2[1].bn2.weight = nn.Parameter(model_ww['layer2.1.bn2.weight'],requires_grad=True)\n",
    "model_unet.layer2[1].bn2.bias = nn.Parameter(model_ww['layer2.1.bn2.bias'],requires_grad=True)\n",
    "model_unet.layer2[1].bn2.running_mean = nn.Parameter(model_ww['layer2.1.bn2.running_mean'],requires_grad=False)\n",
    "model_unet.layer2[1].bn2.running_var = nn.Parameter(model_ww['layer2.1.bn2.running_var'],requires_grad=False)\n",
    "model_unet.layer2[1].bn2.num_batches_tracked = nn.Parameter(model_ww['layer2.1.bn2.num_batches_tracked'],requires_grad=False)\n",
    "\n",
    "model_unet.layer2_1x1[0].weight = nn.Parameter(model_ww['layer2_1x1.0.weight'],requires_grad=True)\n",
    "model_unet.layer2_1x1[0].bias = nn.Parameter(model_ww['layer2_1x1.0.bias'],requires_grad=True)\n",
    "\n",
    "\n",
    "model_unet.layer3[0].conv1.weight = nn.Parameter(model_ww['layer3.0.conv1.weight'],requires_grad=True)\n",
    "model_unet.layer3[0].bn1.weight = nn.Parameter(model_ww['layer3.0.bn1.weight'],requires_grad=True)\n",
    "model_unet.layer3[0].bn1.bias = nn.Parameter(model_ww['layer3.0.bn1.bias'],requires_grad=True)\n",
    "model_unet.layer3[0].bn1.running_mean = nn.Parameter(model_ww['layer3.0.bn1.running_mean'],requires_grad=False)\n",
    "model_unet.layer3[0].bn1.running_var = nn.Parameter(model_ww['layer3.0.bn1.running_var'],requires_grad=False)\n",
    "model_unet.layer3[0].bn1.num_batches_tracked = nn.Parameter(model_ww['layer3.0.bn1.num_batches_tracked'],requires_grad=False)\n",
    "model_unet.layer3[0].conv2.weight = nn.Parameter(model_ww['layer3.0.conv2.weight'],requires_grad=True)\n",
    "model_unet.layer3[0].bn2.weight = nn.Parameter(model_ww['layer3.0.bn2.weight'],requires_grad=True)\n",
    "model_unet.layer3[0].bn2.bias = nn.Parameter(model_ww['layer3.0.bn2.bias'],requires_grad=True)\n",
    "model_unet.layer3[0].bn2.running_mean = nn.Parameter(model_ww['layer3.0.bn2.running_mean'],requires_grad=False)\n",
    "model_unet.layer3[0].bn2.running_var = nn.Parameter(model_ww['layer3.0.bn2.running_var'],requires_grad=False)\n",
    "model_unet.layer3[0].bn2.num_batches_tracked = nn.Parameter(model_ww['layer3.0.bn2.num_batches_tracked'],requires_grad=False)\n",
    "\n",
    "model_unet.layer3[0].downsample[0].weight = nn.Parameter(model_ww['layer3.0.downsample.0.weight'],requires_grad=True)\n",
    "model_unet.layer3[0].downsample[1].weight = nn.Parameter(model_ww['layer3.0.downsample.1.weight'],requires_grad=True)\n",
    "model_unet.layer3[0].downsample[1].bias = nn.Parameter(model_ww[ 'layer3.0.downsample.1.bias'],requires_grad=True)\n",
    "model_unet.layer3[0].downsample[1].running_mean = nn.Parameter(model_ww['layer3.0.downsample.1.running_mean'],requires_grad=False)\n",
    "model_unet.layer3[0].downsample[1].running_var = nn.Parameter(model_ww['layer3.0.downsample.1.running_var'],requires_grad=False)\n",
    "model_unet.layer3[0].downsample[1].num_batches_tracked = nn.Parameter(model_ww['layer3.0.downsample.1.num_batches_tracked'],requires_grad=False)\n",
    "\n",
    "\n",
    "model_unet.layer3[1].conv1.weight = nn.Parameter(model_ww['layer3.1.conv1.weight'],requires_grad=True)\n",
    "model_unet.layer3[1].bn1.weight = nn.Parameter(model_ww['layer3.1.bn1.weight'],requires_grad=True)\n",
    "model_unet.layer3[1].bn1.bias = nn.Parameter(model_ww['layer3.1.bn1.bias'],requires_grad=True)\n",
    "model_unet.layer3[1].bn1.running_mean = nn.Parameter(model_ww['layer3.1.bn1.running_mean'],requires_grad=False)\n",
    "model_unet.layer3[1].bn1.running_var = nn.Parameter(model_ww['layer3.1.bn1.running_var'],requires_grad=False)\n",
    "model_unet.layer3[1].bn1.num_batches_tracked = nn.Parameter(model_ww['layer3.1.bn1.num_batches_tracked'],requires_grad=False)\n",
    "model_unet.layer3[1].conv2.weight = nn.Parameter(model_ww['layer3.1.conv2.weight'],requires_grad=True)\n",
    "model_unet.layer3[1].bn2.weight = nn.Parameter(model_ww['layer3.1.bn2.weight'],requires_grad=True)\n",
    "model_unet.layer3[1].bn2.bias = nn.Parameter(model_ww['layer3.1.bn2.bias'],requires_grad=True)\n",
    "model_unet.layer3[1].bn2.running_mean = nn.Parameter(model_ww['layer3.1.bn2.running_mean'],requires_grad=False)\n",
    "model_unet.layer3[1].bn2.running_var = nn.Parameter(model_ww['layer3.1.bn2.running_var'],requires_grad=False)\n",
    "model_unet.layer3[1].bn2.num_batches_tracked = nn.Parameter(model_ww['layer3.1.bn2.num_batches_tracked'],requires_grad=False)\n",
    "\n",
    "model_unet.layer3_1x1[0].weight = nn.Parameter(model_ww['layer3_1x1.0.weight'],requires_grad=True)\n",
    "model_unet.layer3_1x1[0].bias = nn.Parameter(model_ww['layer3_1x1.0.bias'],requires_grad=True)\n",
    "\n",
    "\n",
    "model_unet.layer4[0].conv1.weight = nn.Parameter(model_ww['layer4.0.conv1.weight'],requires_grad=True)\n",
    "model_unet.layer4[0].bn1.weight = nn.Parameter(model_ww['layer4.0.bn1.weight'],requires_grad=True)\n",
    "model_unet.layer4[0].bn1.bias = nn.Parameter(model_ww['layer4.0.bn1.bias'],requires_grad=True)\n",
    "model_unet.layer4[0].bn1.running_mean = nn.Parameter(model_ww['layer4.0.bn1.running_mean'],requires_grad=False)\n",
    "model_unet.layer4[0].bn1.running_var = nn.Parameter(model_ww['layer4.0.bn1.running_var'],requires_grad=False)\n",
    "model_unet.layer4[0].bn1.num_batches_tracked = nn.Parameter(model_ww['layer4.0.bn1.num_batches_tracked'],requires_grad=False)\n",
    "model_unet.layer4[0].conv2.weight = nn.Parameter(model_ww['layer4.0.conv2.weight'],requires_grad=True)\n",
    "model_unet.layer4[0].bn2.weight = nn.Parameter(model_ww['layer4.0.bn2.weight'],requires_grad=True)\n",
    "model_unet.layer4[0].bn2.bias = nn.Parameter(model_ww['layer4.0.bn2.bias'],requires_grad=True)\n",
    "model_unet.layer4[0].bn2.running_mean = nn.Parameter(model_ww['layer4.0.bn2.running_mean'],requires_grad=False)\n",
    "model_unet.layer4[0].bn2.running_var = nn.Parameter(model_ww['layer4.0.bn2.running_var'],requires_grad=False)\n",
    "model_unet.layer4[0].bn2.num_batches_tracked = nn.Parameter(model_ww['layer4.0.bn2.num_batches_tracked'],requires_grad=False)\n",
    "\n",
    "model_unet.layer4[0].downsample[0].weight = nn.Parameter(model_ww['layer4.0.downsample.0.weight'],requires_grad=True)\n",
    "model_unet.layer4[0].downsample[1].weight = nn.Parameter(model_ww['layer4.0.downsample.1.weight'],requires_grad=True)\n",
    "model_unet.layer4[0].downsample[1].bias = nn.Parameter(model_ww[ 'layer4.0.downsample.1.bias'],requires_grad=True)\n",
    "model_unet.layer4[0].downsample[1].running_mean = nn.Parameter(model_ww['layer4.0.downsample.1.running_mean'],requires_grad=False)\n",
    "model_unet.layer4[0].downsample[1].running_var = nn.Parameter(model_ww['layer4.0.downsample.1.running_var'],requires_grad=False)\n",
    "model_unet.layer4[0].downsample[1].num_batches_tracked = nn.Parameter(model_ww['layer4.0.downsample.1.num_batches_tracked'],requires_grad=False)\n",
    "\n",
    "\n",
    "model_unet.layer4[1].conv1.weight = nn.Parameter(model_ww['layer4.1.conv1.weight'],requires_grad=True)\n",
    "model_unet.layer4[1].bn1.weight = nn.Parameter(model_ww['layer4.1.bn1.weight'],requires_grad=True)\n",
    "model_unet.layer4[1].bn1.bias = nn.Parameter(model_ww['layer4.1.bn1.bias'],requires_grad=True)\n",
    "model_unet.layer4[1].bn1.running_mean = nn.Parameter(model_ww['layer4.1.bn1.running_mean'],requires_grad=False)\n",
    "model_unet.layer4[1].bn1.running_var = nn.Parameter(model_ww['layer4.1.bn1.running_var'],requires_grad=False)\n",
    "model_unet.layer4[1].bn1.num_batches_tracked = nn.Parameter(model_ww['layer4.1.bn1.num_batches_tracked'],requires_grad=False)\n",
    "model_unet.layer4[1].conv2.weight = nn.Parameter(model_ww['layer4.1.conv2.weight'],requires_grad=True)\n",
    "model_unet.layer4[1].bn2.weight = nn.Parameter(model_ww['layer4.1.bn2.weight'],requires_grad=True)\n",
    "model_unet.layer4[1].bn2.bias = nn.Parameter(model_ww['layer4.1.bn2.bias'],requires_grad=True)\n",
    "model_unet.layer4[1].bn2.running_mean = nn.Parameter(model_ww['layer4.1.bn2.running_mean'],requires_grad=False)\n",
    "model_unet.layer4[1].bn2.running_var = nn.Parameter(model_ww['layer4.1.bn2.running_var'],requires_grad=False)\n",
    "model_unet.layer4[1].bn2.num_batches_tracked = nn.Parameter(model_ww['layer4.1.bn2.num_batches_tracked'],requires_grad=False)\n",
    "\n",
    "model_unet.layer4_1x1[0].weight = nn.Parameter(model_ww['layer4_1x1.0.weight'],requires_grad=True)\n",
    "model_unet.layer4_1x1[0].bias = nn.Parameter(model_ww['layer4_1x1.0.bias'],requires_grad=True)\n",
    "\n",
    "model_unet.conv_up3[0].weight = nn.Parameter(model_ww['conv_up3.0.weight'],requires_grad=True)\n",
    "model_unet.conv_up3[0].bias = nn.Parameter(model_ww['conv_up3.0.bias'],requires_grad=True)\n",
    "model_unet.conv_up2[0].weight = nn.Parameter(model_ww['conv_up2.0.weight'],requires_grad=True)\n",
    "model_unet.conv_up2[0].bias = nn.Parameter(model_ww['conv_up2.0.bias'],requires_grad=True)\n",
    "model_unet.conv_up1[0].weight = nn.Parameter(model_ww['conv_up1.0.weight'],requires_grad=True)\n",
    "model_unet.conv_up1[0].bias = nn.Parameter(model_ww['conv_up1.0.bias'],requires_grad=True)\n",
    "model_unet.conv_up0[0].weight = nn.Parameter(model_ww['conv_up0.0.weight'],requires_grad=True)\n",
    "model_unet.conv_up0[0].bias = nn.Parameter(model_ww['conv_up0.0.bias'],requires_grad=True)\n",
    "\n",
    "\n",
    "model_unet.conv_original_size0[0].weight = nn.Parameter(model_ww['conv_original_size0.0.weight'],requires_grad=True)\n",
    "model_unet.conv_original_size0[0].bias = nn.Parameter(model_ww['conv_original_size0.0.bias'],requires_grad=True)\n",
    "model_unet.conv_original_size1[0].weight = nn.Parameter(model_ww['conv_original_size1.0.weight'],requires_grad=True)\n",
    "model_unet.conv_original_size1[0].bias = nn.Parameter(model_ww['conv_original_size1.0.bias'],requires_grad=True)\n",
    "model_unet.conv_original_size2[0].weight = nn.Parameter(model_ww['conv_original_size2.0.weight'],requires_grad=True)\n",
    "model_unet.conv_original_size2[0].bias = nn.Parameter(model_ww['conv_original_size2.0.bias'],requires_grad=True)\n",
    "\n",
    "model_unet.conv_last.weight = nn.Parameter(model_ww['conv_last.weight'],requires_grad=True)\n",
    "model_unet.conv_last.bias = nn.Parameter(model_ww['conv_last.bias'],requires_grad=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function (dice + bce loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_logits(data):\n",
    "    \"\"\"Attempts to guess whether the given PyTorch tensor contains logits.\n",
    "\n",
    "    If the argument `data` contains only values that are no less than 0 and no\n",
    "    greater than 1, then `False` is returned; otherwise, `True` is returned.\n",
    "    \"\"\"\n",
    "    if   (data > 1).any(): return True\n",
    "    elif (data < 0).any(): return True\n",
    "    else:                  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, gold, logits=None, smoothing=1, graph=False, metrics=None):\n",
    "    \"\"\"Returns the loss based on the dice coefficient.\n",
    "    \n",
    "    `dice_loss(pred, gold)` returns the dice-coefficient loss between the\n",
    "    tensors `pred` and `gold` which must be the same shape and which should\n",
    "    represent probabilities. The first two dimensions of both `pred` and `gold`\n",
    "    must represent the batch-size and the classes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred : tensor\n",
    "        The predicted probabilities of each class.\n",
    "    gold : tensor\n",
    "        The gold-standard labels for each class.\n",
    "    logits : boolean, optional\n",
    "        Whether the values in `pred` are logits--i.e., unnormalized scores that\n",
    "        have not been run through a sigmoid calculation already. If this is\n",
    "        `True`, then the BCE starts by calculating the sigmoid of the `pred`\n",
    "        argument. If `None`, then attempts to deduce whether the input is or is\n",
    "        not logits. The default is `None`.\n",
    "    smoothing : number, optional\n",
    "        The smoothing coefficient `s`. The default is `1`.\n",
    "    metrics : dict or None, optional\n",
    "        An optional dictionary into which the key `'dice'` should be inserted\n",
    "        with the dice-loss as the value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The dice-coefficient loss of the prediction.\n",
    "    \"\"\"\n",
    "    pred = pred.contiguous()\n",
    "    gold = gold.contiguous()\n",
    "    if logits is None: logits = is_logits(pred)\n",
    "    if logits: pred = torch.sigmoid(pred)\n",
    "    intersection = (pred * gold)\n",
    "    pred = pred**2\n",
    "    gold = gold**2\n",
    "    while len(intersection.shape) > 2:\n",
    "        intersection = intersection.sum(dim=-1)\n",
    "        pred = pred.sum(dim=-1)\n",
    "        gold = gold.sum(dim=-1)\n",
    "    if smoothing is None: smoothing = 0\n",
    "    loss = (1 - ((2 * intersection + smoothing) / (pred + gold + smoothing)))\n",
    "    # Average the loss across classes then take the mean across batch elements.\n",
    "    loss = loss.mean(dim=1).mean()\n",
    "    if metrics is not None:\n",
    "        if 'dice' not in metrics: metrics['dice'] = 0.0\n",
    "        metrics['dice'] += loss.data.cpu().numpy() * gold.size(0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_loss(pred, gold, logits=None, reweight=True, metrics=None):\n",
    "    \"\"\"Returns the loss based on the binary cross entropy.\n",
    "    \n",
    "    `bce_loss(pred, gold)` returns the binary cross entropy loss between the\n",
    "    tensors `pred` and `gold` which must be the same shape and which should\n",
    "    represent probabilities. The first two dimensions of both `pred` and `gold`\n",
    "    must represent the batch-size and the classes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred : tensor\n",
    "        The predicted probabilities of each class.\n",
    "    gold : tensor\n",
    "        The gold-standard labels for each class.\n",
    "    logits : boolean, optional\n",
    "        Whether the values in `pred` are logits--i.e., unnormalized scores that\n",
    "        have not been run through a sigmoid calculation already. If this is\n",
    "        `True`, then the BCE starts by calculating the sigmoid of the `pred`\n",
    "        argument. If `None`, then attempts to deduce whether the input is or is\n",
    "        not logits. The default is `None`.\n",
    "    reweight : boolean, optional\n",
    "        Whether to reweight the classes by calculating the BCE for each class\n",
    "        then calculating the mean across classes. If `False`, then the raw BCE\n",
    "        across all pixels, classes, and batches is returned (the default).\n",
    "    metrics : dict or None, optional\n",
    "        An optional dictionary into which the key `'bce'` should be inserted\n",
    "        with the dice-loss as the value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The binary cross entropy loss of the prediction.\n",
    "    \"\"\"\n",
    "    if logits is None: logits = is_logits(pred)\n",
    "    if logits: f = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "    else:      f = torch.nn.functional.binary_cross_entropy\n",
    "    if reweight:\n",
    "        n = pred.shape[-1] * pred.shape[-2] * pred.shape[0]\n",
    "        r = 0\n",
    "        for k in range(pred.shape[1]):\n",
    "            (p,t) = (pred[:,[k]], gold[:,[k]])\n",
    "            r += f(p, t) * (n - torch.sum(t)) / n\n",
    "    else:\n",
    "        r = f(pred, gold)\n",
    "    if metrics is not None:\n",
    "        if 'bce' not in metrics: metrics['bce'] = 0.0\n",
    "        metrics['bce'] += r.data.cpu().numpy() * gold.size(0)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_loss(nn.Module):\n",
    "    def __init__(self,bce_weight):\n",
    "        super(my_loss,self).__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs,targets):\n",
    "        bce_l = bce_loss(inputs,targets)*self.bce_weight\n",
    "        dice_l = dice_loss(inputs,targets)*(1-self.bce_weight)\n",
    "        m_l = bce_l + dice_l\n",
    "        return m_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create a file handler and set the level to info\n",
    "file_handler = logging.FileHandler('training_tran_re.log')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Create a stream handler to print the log messages to the console\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Create a formatter and set it for both handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "stream_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handlers to the logger\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first transfer the data to pytorch.tensor version, which is called image_sum.pt and pred_sum.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.load('/scratch/bs4283/visual_autolabel/image_sum.pt')\n",
    "gold =  torch.load('/scratch/bs4283/visual_autolabel/pred_sum.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training process with pre-trained weight, and training with 60 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image, gold, test_size=0.3, random_state= random.randint(3, 999))\n",
    "iters = 60\n",
    "for iteration in range(iters): \n",
    "    if iters < 20:\n",
    "        loss_fn = my_loss(bce_weight = 0.67)\n",
    "        lr = 0.00375\n",
    "    elif iters > 20 and iters < 40 :   \n",
    "        loss_fn = my_loss(bce_weight = 0.33)\n",
    "        lr = 0.00250\n",
    "    elif iters > 40:\n",
    "        loss_fn = my_loss(bce_weight = 0.0)\n",
    "        lr = 0.00125\n",
    "    optimizer = torch.optim.Adam(model_unet.parameters(), lr=lr)\n",
    "    y_pred = model_unet(X_train)\n",
    "    train_loss = loss_fn(y_pred,y_train)\n",
    "    y_valid = model_unet(X_test)\n",
    "    val_loss = loss_fn(y_valid,y_test)\n",
    "    logger.info(f'Epoch {iteration}, Training Loss: {train_loss}, Validation Loss: {val_loss}')\n",
    "    train_loss.requires_grad_(True)\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()              \n",
    "    optimizer.step()   \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_unet,'/scratch/bs4283/visual_autolabel/model_e60.pt')\n",
    "pred_image = model_unet(image)\n",
    "torch.save(pred_image,'/scratch/bs4283/visual_autolabel/model_e60/output_image.pt')\n",
    "torch.save(y_pred,'/scratch/bs4283/visual_autolabel/model_e60/train_output.pt')\n",
    "torch.save(y_valid,'/scratch/bs4283/visual_autolabel/model_e60/valid_output.pt')\n",
    "torch.save(y_train,'/scratch/bs4283/visual_autolabel/model_e60/train_true.pt')\n",
    "torch.save(y_test,'/scratch/bs4283/visual_autolabel/model_e60/valid_true.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model for 5 samples training with 300 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image, gold, test_size=0.3, random_state= random.randint(3, 999))\n",
    "\n",
    "iters = 300\n",
    "for iteration in range(iters): \n",
    "    if iters < 100:\n",
    "        loss_fn = my_loss(bce_weight = 0.67)\n",
    "        lr = 0.00375\n",
    "    elif iters > 100 and iters < 200 :   \n",
    "        loss_fn = my_loss(bce_weight = 0.33)\n",
    "        lr = 0.00250\n",
    "    elif iters > 200:\n",
    "        loss_fn = my_loss(bce_weight = 0.0)\n",
    "        lr = 0.00125  \n",
    "    optimizer = torch.optim.Adam(model_unet.parameters(), lr=lr)\n",
    "    x_sample_train,_ ,y_sample_train,_ , = train_test_split(X_train, y_train, test_size=0.83, random_state= random.randint(3, 999))\n",
    "    sample_t_pred = model_unet(x_sample_train)\n",
    "    sample_loss = loss_fn(sample_t_pred,y_sample_train)\n",
    "    y_pred = model_unet(X_train)\n",
    "    train_loss = loss_fn(y_pred,y_train)\n",
    "    y_valid = model_unet(X_test)\n",
    "    val_loss = loss_fn(y_valid,y_test)\n",
    "    logger.info(f'Epoch {iteration}, Training Loss: {train_loss}, Sample loss: {sample_loss}, Validation Loss: {val_loss}')\n",
    "    sample_loss.requires_grad_(True)\n",
    "    optimizer.zero_grad()\n",
    "    sample_loss.backward()              \n",
    "    optimizer.step()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log show. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-23 13:58:00,282 - INFO - Epoch 0, Training Loss: 0.7129805684089661, Validation Loss: 0.6832046508789062\n",
      "2023-09-23 13:58:00,282 - INFO - Epoch 0, Training Loss: 0.7129805684089661, Validation Loss: 0.6832046508789062\n",
      "2023-09-23 13:58:00,282 - INFO - Epoch 0, Training Loss: 0.7129805684089661, Validation Loss: 0.6832046508789062\n",
      "2023-09-23 13:58:10,547 - INFO - Epoch 1, Training Loss: 0.5419676303863525, Validation Loss: 0.5152378678321838\n",
      "2023-09-23 13:58:10,547 - INFO - Epoch 1, Training Loss: 0.5419676303863525, Validation Loss: 0.5152378678321838\n",
      "2023-09-23 13:58:10,547 - INFO - Epoch 1, Training Loss: 0.5419676303863525, Validation Loss: 0.5152378678321838\n",
      "2023-09-23 13:58:20,799 - INFO - Epoch 2, Training Loss: 0.4520067572593689, Validation Loss: 0.4290185272693634\n",
      "2023-09-23 13:58:20,799 - INFO - Epoch 2, Training Loss: 0.4520067572593689, Validation Loss: 0.4290185272693634\n",
      "2023-09-23 13:58:20,799 - INFO - Epoch 2, Training Loss: 0.4520067572593689, Validation Loss: 0.4290185272693634\n",
      "2023-09-23 13:58:29,274 - INFO - Epoch 3, Training Loss: 0.41666263341903687, Validation Loss: 0.41201719641685486\n",
      "2023-09-23 13:58:29,274 - INFO - Epoch 3, Training Loss: 0.41666263341903687, Validation Loss: 0.41201719641685486\n",
      "2023-09-23 13:58:29,274 - INFO - Epoch 3, Training Loss: 0.41666263341903687, Validation Loss: 0.41201719641685486\n",
      "2023-09-23 13:58:41,675 - INFO - Epoch 4, Training Loss: 0.3704700171947479, Validation Loss: 0.35750770568847656\n",
      "2023-09-23 13:58:41,675 - INFO - Epoch 4, Training Loss: 0.3704700171947479, Validation Loss: 0.35750770568847656\n",
      "2023-09-23 13:58:41,675 - INFO - Epoch 4, Training Loss: 0.3704700171947479, Validation Loss: 0.35750770568847656\n",
      "2023-09-23 13:58:49,418 - INFO - Epoch 5, Training Loss: 0.3547137379646301, Validation Loss: 0.36290690302848816\n",
      "2023-09-23 13:58:49,418 - INFO - Epoch 5, Training Loss: 0.3547137379646301, Validation Loss: 0.36290690302848816\n",
      "2023-09-23 13:58:49,418 - INFO - Epoch 5, Training Loss: 0.3547137379646301, Validation Loss: 0.36290690302848816\n",
      "2023-09-23 13:59:01,246 - INFO - Epoch 6, Training Loss: 0.3302263617515564, Validation Loss: 0.3231668770313263\n",
      "2023-09-23 13:59:01,246 - INFO - Epoch 6, Training Loss: 0.3302263617515564, Validation Loss: 0.3231668770313263\n",
      "2023-09-23 13:59:01,246 - INFO - Epoch 6, Training Loss: 0.3302263617515564, Validation Loss: 0.3231668770313263\n",
      "2023-09-23 13:59:15,761 - INFO - Epoch 7, Training Loss: 0.3204410970211029, Validation Loss: 0.33274954557418823\n",
      "2023-09-23 13:59:15,761 - INFO - Epoch 7, Training Loss: 0.3204410970211029, Validation Loss: 0.33274954557418823\n",
      "2023-09-23 13:59:15,761 - INFO - Epoch 7, Training Loss: 0.3204410970211029, Validation Loss: 0.33274954557418823\n",
      "2023-09-23 13:59:30,189 - INFO - Epoch 8, Training Loss: 0.30480876564979553, Validation Loss: 0.30142706632614136\n",
      "2023-09-23 13:59:30,189 - INFO - Epoch 8, Training Loss: 0.30480876564979553, Validation Loss: 0.30142706632614136\n",
      "2023-09-23 13:59:30,189 - INFO - Epoch 8, Training Loss: 0.30480876564979553, Validation Loss: 0.30142706632614136\n",
      "2023-09-23 13:59:38,216 - INFO - Epoch 9, Training Loss: 0.2969009280204773, Validation Loss: 0.31144317984580994\n",
      "2023-09-23 13:59:38,216 - INFO - Epoch 9, Training Loss: 0.2969009280204773, Validation Loss: 0.31144317984580994\n",
      "2023-09-23 13:59:38,216 - INFO - Epoch 9, Training Loss: 0.2969009280204773, Validation Loss: 0.31144317984580994\n",
      "2023-09-23 13:59:50,003 - INFO - Epoch 10, Training Loss: 0.2856288254261017, Validation Loss: 0.2854282855987549\n",
      "2023-09-23 13:59:50,003 - INFO - Epoch 10, Training Loss: 0.2856288254261017, Validation Loss: 0.2854282855987549\n",
      "2023-09-23 13:59:50,003 - INFO - Epoch 10, Training Loss: 0.2856288254261017, Validation Loss: 0.2854282855987549\n",
      "2023-09-23 14:00:00,383 - INFO - Epoch 11, Training Loss: 0.2795182466506958, Validation Loss: 0.2963794767856598\n",
      "2023-09-23 14:00:00,383 - INFO - Epoch 11, Training Loss: 0.2795182466506958, Validation Loss: 0.2963794767856598\n",
      "2023-09-23 14:00:00,383 - INFO - Epoch 11, Training Loss: 0.2795182466506958, Validation Loss: 0.2963794767856598\n",
      "2023-09-23 14:00:07,030 - INFO - Epoch 12, Training Loss: 0.2712511718273163, Validation Loss: 0.2750900387763977\n",
      "2023-09-23 14:00:07,030 - INFO - Epoch 12, Training Loss: 0.2712511718273163, Validation Loss: 0.2750900387763977\n",
      "2023-09-23 14:00:07,030 - INFO - Epoch 12, Training Loss: 0.2712511718273163, Validation Loss: 0.2750900387763977\n",
      "2023-09-23 14:00:13,929 - INFO - Epoch 13, Training Loss: 0.26596373319625854, Validation Loss: 0.2864006757736206\n",
      "2023-09-23 14:00:13,929 - INFO - Epoch 13, Training Loss: 0.26596373319625854, Validation Loss: 0.2864006757736206\n",
      "2023-09-23 14:00:13,929 - INFO - Epoch 13, Training Loss: 0.26596373319625854, Validation Loss: 0.2864006757736206\n",
      "2023-09-23 14:00:22,371 - INFO - Epoch 14, Training Loss: 0.25995954871177673, Validation Loss: 0.26875394582748413\n",
      "2023-09-23 14:00:22,371 - INFO - Epoch 14, Training Loss: 0.25995954871177673, Validation Loss: 0.26875394582748413\n",
      "2023-09-23 14:00:22,371 - INFO - Epoch 14, Training Loss: 0.25995954871177673, Validation Loss: 0.26875394582748413\n",
      "2023-09-23 14:00:29,132 - INFO - Epoch 15, Training Loss: 0.2571149468421936, Validation Loss: 0.27520012855529785\n",
      "2023-09-23 14:00:29,132 - INFO - Epoch 15, Training Loss: 0.2571149468421936, Validation Loss: 0.27520012855529785\n",
      "2023-09-23 14:00:29,132 - INFO - Epoch 15, Training Loss: 0.2571149468421936, Validation Loss: 0.27520012855529785\n",
      "2023-09-23 14:00:36,974 - INFO - Epoch 16, Training Loss: 0.2536798417568207, Validation Loss: 0.2682899534702301\n",
      "2023-09-23 14:00:36,974 - INFO - Epoch 16, Training Loss: 0.2536798417568207, Validation Loss: 0.2682899534702301\n",
      "2023-09-23 14:00:36,974 - INFO - Epoch 16, Training Loss: 0.2536798417568207, Validation Loss: 0.2682899534702301\n",
      "2023-09-23 14:00:43,924 - INFO - Epoch 17, Training Loss: 0.2502753436565399, Validation Loss: 0.26623839139938354\n",
      "2023-09-23 14:00:43,924 - INFO - Epoch 17, Training Loss: 0.2502753436565399, Validation Loss: 0.26623839139938354\n",
      "2023-09-23 14:00:43,924 - INFO - Epoch 17, Training Loss: 0.2502753436565399, Validation Loss: 0.26623839139938354\n",
      "2023-09-23 14:00:50,234 - INFO - Epoch 18, Training Loss: 0.2436199188232422, Validation Loss: 0.2616586685180664\n",
      "2023-09-23 14:00:50,234 - INFO - Epoch 18, Training Loss: 0.2436199188232422, Validation Loss: 0.2616586685180664\n",
      "2023-09-23 14:00:50,234 - INFO - Epoch 18, Training Loss: 0.2436199188232422, Validation Loss: 0.2616586685180664\n",
      "2023-09-23 14:00:57,396 - INFO - Epoch 19, Training Loss: 0.23953109979629517, Validation Loss: 0.2563841938972473\n",
      "2023-09-23 14:00:57,396 - INFO - Epoch 19, Training Loss: 0.23953109979629517, Validation Loss: 0.2563841938972473\n",
      "2023-09-23 14:00:57,396 - INFO - Epoch 19, Training Loss: 0.23953109979629517, Validation Loss: 0.2563841938972473\n",
      "2023-09-23 14:01:04,996 - INFO - Epoch 20, Training Loss: 0.23335522413253784, Validation Loss: 0.2550562024116516\n",
      "2023-09-23 14:01:04,996 - INFO - Epoch 20, Training Loss: 0.23335522413253784, Validation Loss: 0.2550562024116516\n",
      "2023-09-23 14:01:04,996 - INFO - Epoch 20, Training Loss: 0.23335522413253784, Validation Loss: 0.2550562024116516\n",
      "2023-09-23 14:01:12,782 - INFO - Epoch 21, Training Loss: 0.23209069669246674, Validation Loss: 0.24972595274448395\n",
      "2023-09-23 14:01:12,782 - INFO - Epoch 21, Training Loss: 0.23209069669246674, Validation Loss: 0.24972595274448395\n",
      "2023-09-23 14:01:12,782 - INFO - Epoch 21, Training Loss: 0.23209069669246674, Validation Loss: 0.24972595274448395\n",
      "2023-09-23 14:01:22,303 - INFO - Epoch 22, Training Loss: 0.22791029512882233, Validation Loss: 0.2512121796607971\n",
      "2023-09-23 14:01:22,303 - INFO - Epoch 22, Training Loss: 0.22791029512882233, Validation Loss: 0.2512121796607971\n",
      "2023-09-23 14:01:22,303 - INFO - Epoch 22, Training Loss: 0.22791029512882233, Validation Loss: 0.2512121796607971\n",
      "2023-09-23 14:01:31,521 - INFO - Epoch 23, Training Loss: 0.22691556811332703, Validation Loss: 0.24139025807380676\n",
      "2023-09-23 14:01:31,521 - INFO - Epoch 23, Training Loss: 0.22691556811332703, Validation Loss: 0.24139025807380676\n",
      "2023-09-23 14:01:31,521 - INFO - Epoch 23, Training Loss: 0.22691556811332703, Validation Loss: 0.24139025807380676\n",
      "2023-09-23 14:01:38,259 - INFO - Epoch 24, Training Loss: 0.22211185097694397, Validation Loss: 0.24917806684970856\n",
      "2023-09-23 14:01:38,259 - INFO - Epoch 24, Training Loss: 0.22211185097694397, Validation Loss: 0.24917806684970856\n",
      "2023-09-23 14:01:38,259 - INFO - Epoch 24, Training Loss: 0.22211185097694397, Validation Loss: 0.24917806684970856\n",
      "2023-09-23 14:01:45,498 - INFO - Epoch 25, Training Loss: 0.22091984748840332, Validation Loss: 0.23883359134197235\n",
      "2023-09-23 14:01:45,498 - INFO - Epoch 25, Training Loss: 0.22091984748840332, Validation Loss: 0.23883359134197235\n",
      "2023-09-23 14:01:45,498 - INFO - Epoch 25, Training Loss: 0.22091984748840332, Validation Loss: 0.23883359134197235\n",
      "2023-09-23 14:01:51,513 - INFO - Epoch 26, Training Loss: 0.21650220453739166, Validation Loss: 0.246619313955307\n",
      "2023-09-23 14:01:51,513 - INFO - Epoch 26, Training Loss: 0.21650220453739166, Validation Loss: 0.246619313955307\n",
      "2023-09-23 14:01:51,513 - INFO - Epoch 26, Training Loss: 0.21650220453739166, Validation Loss: 0.246619313955307\n",
      "2023-09-23 14:01:58,729 - INFO - Epoch 27, Training Loss: 0.2150401473045349, Validation Loss: 0.2380983680486679\n",
      "2023-09-23 14:01:58,729 - INFO - Epoch 27, Training Loss: 0.2150401473045349, Validation Loss: 0.2380983680486679\n",
      "2023-09-23 14:01:58,729 - INFO - Epoch 27, Training Loss: 0.2150401473045349, Validation Loss: 0.2380983680486679\n",
      "2023-09-23 14:02:04,878 - INFO - Epoch 28, Training Loss: 0.2112727016210556, Validation Loss: 0.24278709292411804\n",
      "2023-09-23 14:02:04,878 - INFO - Epoch 28, Training Loss: 0.2112727016210556, Validation Loss: 0.24278709292411804\n",
      "2023-09-23 14:02:04,878 - INFO - Epoch 28, Training Loss: 0.2112727016210556, Validation Loss: 0.24278709292411804\n",
      "2023-09-23 14:02:11,437 - INFO - Epoch 29, Training Loss: 0.20933204889297485, Validation Loss: 0.23597171902656555\n",
      "2023-09-23 14:02:11,437 - INFO - Epoch 29, Training Loss: 0.20933204889297485, Validation Loss: 0.23597171902656555\n",
      "2023-09-23 14:02:11,437 - INFO - Epoch 29, Training Loss: 0.20933204889297485, Validation Loss: 0.23597171902656555\n",
      "2023-09-23 14:02:17,568 - INFO - Epoch 30, Training Loss: 0.20641276240348816, Validation Loss: 0.2395799458026886\n",
      "2023-09-23 14:02:17,568 - INFO - Epoch 30, Training Loss: 0.20641276240348816, Validation Loss: 0.2395799458026886\n",
      "2023-09-23 14:02:17,568 - INFO - Epoch 30, Training Loss: 0.20641276240348816, Validation Loss: 0.2395799458026886\n",
      "2023-09-23 14:02:27,145 - INFO - Epoch 31, Training Loss: 0.20448942482471466, Validation Loss: 0.2307840883731842\n",
      "2023-09-23 14:02:27,145 - INFO - Epoch 31, Training Loss: 0.20448942482471466, Validation Loss: 0.2307840883731842\n",
      "2023-09-23 14:02:27,145 - INFO - Epoch 31, Training Loss: 0.20448942482471466, Validation Loss: 0.2307840883731842\n",
      "2023-09-23 14:02:35,030 - INFO - Epoch 32, Training Loss: 0.20271137356758118, Validation Loss: 0.2377919852733612\n",
      "2023-09-23 14:02:35,030 - INFO - Epoch 32, Training Loss: 0.20271137356758118, Validation Loss: 0.2377919852733612\n",
      "2023-09-23 14:02:35,030 - INFO - Epoch 32, Training Loss: 0.20271137356758118, Validation Loss: 0.2377919852733612\n",
      "2023-09-23 14:02:45,173 - INFO - Epoch 33, Training Loss: 0.2003978043794632, Validation Loss: 0.22931286692619324\n",
      "2023-09-23 14:02:45,173 - INFO - Epoch 33, Training Loss: 0.2003978043794632, Validation Loss: 0.22931286692619324\n",
      "2023-09-23 14:02:45,173 - INFO - Epoch 33, Training Loss: 0.2003978043794632, Validation Loss: 0.22931286692619324\n",
      "2023-09-23 14:02:53,318 - INFO - Epoch 34, Training Loss: 0.1995735615491867, Validation Loss: 0.23715978860855103\n",
      "2023-09-23 14:02:53,318 - INFO - Epoch 34, Training Loss: 0.1995735615491867, Validation Loss: 0.23715978860855103\n",
      "2023-09-23 14:02:53,318 - INFO - Epoch 34, Training Loss: 0.1995735615491867, Validation Loss: 0.23715978860855103\n",
      "2023-09-23 14:02:59,880 - INFO - Epoch 35, Training Loss: 0.19655558466911316, Validation Loss: 0.2277546525001526\n",
      "2023-09-23 14:02:59,880 - INFO - Epoch 35, Training Loss: 0.19655558466911316, Validation Loss: 0.2277546525001526\n",
      "2023-09-23 14:02:59,880 - INFO - Epoch 35, Training Loss: 0.19655558466911316, Validation Loss: 0.2277546525001526\n",
      "2023-09-23 14:03:07,114 - INFO - Epoch 36, Training Loss: 0.19675947725772858, Validation Loss: 0.23416998982429504\n",
      "2023-09-23 14:03:07,114 - INFO - Epoch 36, Training Loss: 0.19675947725772858, Validation Loss: 0.23416998982429504\n",
      "2023-09-23 14:03:07,114 - INFO - Epoch 36, Training Loss: 0.19675947725772858, Validation Loss: 0.23416998982429504\n",
      "2023-09-23 14:03:15,561 - INFO - Epoch 37, Training Loss: 0.1937735378742218, Validation Loss: 0.22639653086662292\n",
      "2023-09-23 14:03:15,561 - INFO - Epoch 37, Training Loss: 0.1937735378742218, Validation Loss: 0.22639653086662292\n",
      "2023-09-23 14:03:15,561 - INFO - Epoch 37, Training Loss: 0.1937735378742218, Validation Loss: 0.22639653086662292\n",
      "2023-09-23 14:03:22,807 - INFO - Epoch 38, Training Loss: 0.19441932439804077, Validation Loss: 0.231063112616539\n",
      "2023-09-23 14:03:22,807 - INFO - Epoch 38, Training Loss: 0.19441932439804077, Validation Loss: 0.231063112616539\n",
      "2023-09-23 14:03:22,807 - INFO - Epoch 38, Training Loss: 0.19441932439804077, Validation Loss: 0.231063112616539\n",
      "2023-09-23 14:03:45,166 - INFO - Epoch 39, Training Loss: 0.19048051536083221, Validation Loss: 0.22549504041671753\n",
      "2023-09-23 14:03:45,166 - INFO - Epoch 39, Training Loss: 0.19048051536083221, Validation Loss: 0.22549504041671753\n",
      "2023-09-23 14:03:45,166 - INFO - Epoch 39, Training Loss: 0.19048051536083221, Validation Loss: 0.22549504041671753\n",
      "2023-09-23 14:03:54,125 - INFO - Epoch 40, Training Loss: 0.19020693004131317, Validation Loss: 0.2274191975593567\n",
      "2023-09-23 14:03:54,125 - INFO - Epoch 40, Training Loss: 0.19020693004131317, Validation Loss: 0.2274191975593567\n",
      "2023-09-23 14:03:54,125 - INFO - Epoch 40, Training Loss: 0.19020693004131317, Validation Loss: 0.2274191975593567\n",
      "2023-09-23 14:04:02,008 - INFO - Epoch 41, Training Loss: 0.18705762922763824, Validation Loss: 0.22236691415309906\n",
      "2023-09-23 14:04:02,008 - INFO - Epoch 41, Training Loss: 0.18705762922763824, Validation Loss: 0.22236691415309906\n",
      "2023-09-23 14:04:02,008 - INFO - Epoch 41, Training Loss: 0.18705762922763824, Validation Loss: 0.22236691415309906\n",
      "2023-09-23 14:04:09,916 - INFO - Epoch 42, Training Loss: 0.18849804997444153, Validation Loss: 0.22738781571388245\n",
      "2023-09-23 14:04:09,916 - INFO - Epoch 42, Training Loss: 0.18849804997444153, Validation Loss: 0.22738781571388245\n",
      "2023-09-23 14:04:09,916 - INFO - Epoch 42, Training Loss: 0.18849804997444153, Validation Loss: 0.22738781571388245\n",
      "2023-09-23 14:04:18,820 - INFO - Epoch 43, Training Loss: 0.18570706248283386, Validation Loss: 0.21852394938468933\n",
      "2023-09-23 14:04:18,820 - INFO - Epoch 43, Training Loss: 0.18570706248283386, Validation Loss: 0.21852394938468933\n",
      "2023-09-23 14:04:18,820 - INFO - Epoch 43, Training Loss: 0.18570706248283386, Validation Loss: 0.21852394938468933\n",
      "2023-09-23 14:04:28,285 - INFO - Epoch 44, Training Loss: 0.18645872175693512, Validation Loss: 0.22773966193199158\n",
      "2023-09-23 14:04:28,285 - INFO - Epoch 44, Training Loss: 0.18645872175693512, Validation Loss: 0.22773966193199158\n",
      "2023-09-23 14:04:28,285 - INFO - Epoch 44, Training Loss: 0.18645872175693512, Validation Loss: 0.22773966193199158\n",
      "2023-09-23 14:04:35,291 - INFO - Epoch 45, Training Loss: 0.18271899223327637, Validation Loss: 0.21973825991153717\n",
      "2023-09-23 14:04:35,291 - INFO - Epoch 45, Training Loss: 0.18271899223327637, Validation Loss: 0.21973825991153717\n",
      "2023-09-23 14:04:35,291 - INFO - Epoch 45, Training Loss: 0.18271899223327637, Validation Loss: 0.21973825991153717\n",
      "2023-09-23 14:04:42,018 - INFO - Epoch 46, Training Loss: 0.18304747343063354, Validation Loss: 0.22457052767276764\n",
      "2023-09-23 14:04:42,018 - INFO - Epoch 46, Training Loss: 0.18304747343063354, Validation Loss: 0.22457052767276764\n",
      "2023-09-23 14:04:42,018 - INFO - Epoch 46, Training Loss: 0.18304747343063354, Validation Loss: 0.22457052767276764\n",
      "2023-09-23 14:04:48,828 - INFO - Epoch 47, Training Loss: 0.17997385561466217, Validation Loss: 0.22386527061462402\n",
      "2023-09-23 14:04:48,828 - INFO - Epoch 47, Training Loss: 0.17997385561466217, Validation Loss: 0.22386527061462402\n",
      "2023-09-23 14:04:48,828 - INFO - Epoch 47, Training Loss: 0.17997385561466217, Validation Loss: 0.22386527061462402\n",
      "2023-09-23 14:04:55,650 - INFO - Epoch 48, Training Loss: 0.1825757771730423, Validation Loss: 0.22073791921138763\n",
      "2023-09-23 14:04:55,650 - INFO - Epoch 48, Training Loss: 0.1825757771730423, Validation Loss: 0.22073791921138763\n",
      "2023-09-23 14:04:55,650 - INFO - Epoch 48, Training Loss: 0.1825757771730423, Validation Loss: 0.22073791921138763\n",
      "2023-09-23 14:05:05,447 - INFO - Epoch 49, Training Loss: 0.1888314038515091, Validation Loss: 0.22847315669059753\n",
      "2023-09-23 14:05:05,447 - INFO - Epoch 49, Training Loss: 0.1888314038515091, Validation Loss: 0.22847315669059753\n",
      "2023-09-23 14:05:05,447 - INFO - Epoch 49, Training Loss: 0.1888314038515091, Validation Loss: 0.22847315669059753\n",
      "2023-09-23 14:05:15,646 - INFO - Epoch 50, Training Loss: 0.18468306958675385, Validation Loss: 0.2236759066581726\n",
      "2023-09-23 14:05:15,646 - INFO - Epoch 50, Training Loss: 0.18468306958675385, Validation Loss: 0.2236759066581726\n",
      "2023-09-23 14:05:15,646 - INFO - Epoch 50, Training Loss: 0.18468306958675385, Validation Loss: 0.2236759066581726\n",
      "2023-09-23 14:05:27,590 - INFO - Epoch 51, Training Loss: 0.18765310943126678, Validation Loss: 0.22060921788215637\n",
      "2023-09-23 14:05:27,590 - INFO - Epoch 51, Training Loss: 0.18765310943126678, Validation Loss: 0.22060921788215637\n",
      "2023-09-23 14:05:27,590 - INFO - Epoch 51, Training Loss: 0.18765310943126678, Validation Loss: 0.22060921788215637\n",
      "2023-09-23 14:05:38,494 - INFO - Epoch 52, Training Loss: 0.18214702606201172, Validation Loss: 0.22825005650520325\n",
      "2023-09-23 14:05:38,494 - INFO - Epoch 52, Training Loss: 0.18214702606201172, Validation Loss: 0.22825005650520325\n",
      "2023-09-23 14:05:38,494 - INFO - Epoch 52, Training Loss: 0.18214702606201172, Validation Loss: 0.22825005650520325\n",
      "2023-09-23 14:05:46,388 - INFO - Epoch 53, Training Loss: 0.18374767899513245, Validation Loss: 0.21630260348320007\n",
      "2023-09-23 14:05:46,388 - INFO - Epoch 53, Training Loss: 0.18374767899513245, Validation Loss: 0.21630260348320007\n",
      "2023-09-23 14:05:46,388 - INFO - Epoch 53, Training Loss: 0.18374767899513245, Validation Loss: 0.21630260348320007\n",
      "2023-09-23 14:05:54,236 - INFO - Epoch 54, Training Loss: 0.17833808064460754, Validation Loss: 0.22637557983398438\n",
      "2023-09-23 14:05:54,236 - INFO - Epoch 54, Training Loss: 0.17833808064460754, Validation Loss: 0.22637557983398438\n",
      "2023-09-23 14:05:54,236 - INFO - Epoch 54, Training Loss: 0.17833808064460754, Validation Loss: 0.22637557983398438\n",
      "2023-09-23 14:06:01,538 - INFO - Epoch 55, Training Loss: 0.17907167971134186, Validation Loss: 0.2145843505859375\n",
      "2023-09-23 14:06:01,538 - INFO - Epoch 55, Training Loss: 0.17907167971134186, Validation Loss: 0.2145843505859375\n",
      "2023-09-23 14:06:01,538 - INFO - Epoch 55, Training Loss: 0.17907167971134186, Validation Loss: 0.2145843505859375\n",
      "2023-09-23 14:06:10,443 - INFO - Epoch 56, Training Loss: 0.17512257397174835, Validation Loss: 0.2247786819934845\n",
      "2023-09-23 14:06:10,443 - INFO - Epoch 56, Training Loss: 0.17512257397174835, Validation Loss: 0.2247786819934845\n",
      "2023-09-23 14:06:10,443 - INFO - Epoch 56, Training Loss: 0.17512257397174835, Validation Loss: 0.2247786819934845\n",
      "2023-09-23 14:06:20,335 - INFO - Epoch 57, Training Loss: 0.17530785501003265, Validation Loss: 0.21374069154262543\n",
      "2023-09-23 14:06:20,335 - INFO - Epoch 57, Training Loss: 0.17530785501003265, Validation Loss: 0.21374069154262543\n",
      "2023-09-23 14:06:20,335 - INFO - Epoch 57, Training Loss: 0.17530785501003265, Validation Loss: 0.21374069154262543\n",
      "2023-09-23 14:06:31,543 - INFO - Epoch 58, Training Loss: 0.17230963706970215, Validation Loss: 0.2231491357088089\n",
      "2023-09-23 14:06:31,543 - INFO - Epoch 58, Training Loss: 0.17230963706970215, Validation Loss: 0.2231491357088089\n",
      "2023-09-23 14:06:31,543 - INFO - Epoch 58, Training Loss: 0.17230963706970215, Validation Loss: 0.2231491357088089\n",
      "2023-09-23 14:06:41,129 - INFO - Epoch 59, Training Loss: 0.17218658328056335, Validation Loss: 0.2125512659549713\n",
      "2023-09-23 14:06:41,129 - INFO - Epoch 59, Training Loss: 0.17218658328056335, Validation Loss: 0.2125512659549713\n",
      "2023-09-23 14:06:41,129 - INFO - Epoch 59, Training Loss: 0.17218658328056335, Validation Loss: 0.2125512659549713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('training.log', 'r') as file:\n",
    "    contents = file.read()\n",
    "\n",
    "print(contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

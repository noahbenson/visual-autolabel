{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual-Area Autolabeler: Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Noah C. Benson](mailto:nben@uw.edu)$^{1,2,3}$, [Shaoling Chen](mailto:sc6995@nyu.edu)$^{4}$, and [Jonathan Winawer](mailto:jonathan.winawer@nyu.edu)$^{1,2}$\n",
    "\n",
    "$^1$Department of Psychology  \n",
    "$^2$Center for Neural Sciences  \n",
    "$^4$Courant Institute for Mathematics  \n",
    "New York University  \n",
    "New York, NY 10012\n",
    "\n",
    "$^3$**Current Affiliation:**  \n",
    "eScience Institute  \n",
    "University of Washington  \n",
    "Seattle, WA 98195"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define any configuration item that needs to be set locally for the system running this notebook. Most likely, you will have to edit these in order for the model to work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cache_path\n",
    "# The directory into which data for the model training should be cached. This\n",
    "# can be None, but if it is, then the training images will need to be\n",
    "# regenerated every time the notebook is run.\n",
    "data_cache_path  = '/data/visual-autolabel/data'\n",
    "\n",
    "# model_cache_path\n",
    "# The directory into which to store models that are generated during training.\n",
    "# This may be None, but if it is, then the best models will not be saved out to\n",
    "# disk during rounds of training.\n",
    "model_cache_path = '/data/visual-autolabel/models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pimms, pandas, json\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import nibabel as nib\n",
    "import pyrsistent as pyr\n",
    "import neuropythy as ny\n",
    "import torch, torchvision, torchsummary\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import ipyvolume as ipv\n",
    "\n",
    "import visual_autolabel as va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional matplotlib preferences; these are just display preferences.\n",
    "mpl_font_config = {'family':'sans-serif',\n",
    "                   'sans-serif':['HelveticaNeue', 'Helvetica', 'Arial'],\n",
    "                   'size': 10,\n",
    "                   'weight': 'light'}\n",
    "mpl.rc('font', **mpl_font_config)\n",
    "# We want relatively high-res images, especially when saving to disk.\n",
    "mpl.rcParams['figure.dpi'] = 72*4\n",
    "mpl.rcParams['savefig.dpi'] = 72*8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_until(training_plan, until=None, model_key=None,\n",
    "                model_cache_path=model_cache_path,\n",
    "                data_cache_path=data_cache_path,\n",
    "                create_directories=True,\n",
    "                create_mode=0o755):\n",
    "    \"\"\"Continuously runs the given training plan for models until an interrupt.\n",
    "        \n",
    "    Runs training on `'anat'`, `'func'`, and `'both'` models, sequentially,\n",
    "    using random partitions until a keyboard interrupt is caught, at which\n",
    "    point a `pandas` dataframe of the results is returned. The partition is\n",
    "    generated only once per group of model trainings (i.e., per training of an\n",
    "    anatomical, functional, and combined model).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    training_plan : list of dicts\n",
    "        The training-plan to pass to the `visual_autolabel.run_modelplan()`\n",
    "        function.\n",
    "    model_key : str or None, optional\n",
    "        A string that should be appended, as a sub-directory name, to the\n",
    "        `model_cache_path`; this argument allows one to save model training\n",
    "        to a specific sub-directory of the `model_cache_path` directory.\n",
    "    model_cache_path : str, optional\n",
    "        The cache-path to use for the model training. By default, this is the\n",
    "        global variable `model_cache_path`, defined above.\n",
    "    data_cache_path : str, optional\n",
    "        The cache-path from which data for the model training should be loaded.\n",
    "        By default, this is the global variable `data_cache_path`, defined\n",
    "        above.\n",
    "    until : int or None, optional\n",
    "        If an integer is provided, then only `until` groups of trainings are\n",
    "        performed, then the result is returned. If `None`, then the training\n",
    "        continues until a `KeyboardInterrupt` is caught. The default is `None`.\n",
    "    create_directories : boolean, optional\n",
    "        Whether to create cache directories that do not exist (default `True`).\n",
    "    create_mode : int, optional\n",
    "        What mode to use when creating directories (default: `0o755`).\n",
    "    \"\"\"\n",
    "    if data_cache_path is Ellipsis:\n",
    "        data_cache_path = globals()['data_cache_path']\n",
    "    if model_cache_path is Ellipsis:\n",
    "        model_cache_path = globals()['model_cache_path']\n",
    "    if model_key is not None:\n",
    "        if model_cache_path is None:\n",
    "            model_cache_path = model_key\n",
    "        else:\n",
    "            model_cache_path = os.path.join(model_cache_path, model_key)\n",
    "    if not os.path.isdir(model_cache_path) and create_directories:\n",
    "        os.makedirs(model_cache_path, create_mode)\n",
    "    if not os.path.isdir(data_cache_path) and create_directories:\n",
    "        os.makedirs(data_cache_path, create_mode)\n",
    "    training_history = []\n",
    "    datatype_tr = dict(anat='Anatomical Data Only',\n",
    "                       func='Functional Data Only',\n",
    "                       both='Anatomical & Functional Data')\n",
    "    try:\n",
    "        print('')\n",
    "        iterno = 0\n",
    "        while True:\n",
    "            if until is not None and iterno >= until: break\n",
    "            iterno += 1\n",
    "            # Make one partition for all three minimization types.\n",
    "            part = va.partition(va.sids, how=(0.8, 0.2))\n",
    "            pid = va.partition_id(part)\n",
    "            print('%-15s%70s' % ('Iteration %d' % iterno,\n",
    "                                 'Partition ID: %s' % pid))\n",
    "            print('=' * 85)\n",
    "            for (dtype,dnm) in datatype_tr.items():\n",
    "                print('')\n",
    "                print(dnm + ' ' + '-'*(85 - len(dnm) - 1))\n",
    "                print('')\n",
    "                t0 = time.time()\n",
    "                (model, loss, dice) = va.train.run_modelplan(\n",
    "                    training_plan,\n",
    "                    partition=part,\n",
    "                    features=dtype,\n",
    "                    model_cache_path=model_cache_path,\n",
    "                    data_cache_path=data_cache_path)\n",
    "                t1 = time.time()\n",
    "                row = dict(input=dtype, loss=loss, dice=dice,\n",
    "                           training_time=(t1-t0))\n",
    "                training_history.append(row)\n",
    "                print('')\n",
    "    except KeyboardInterrupt:\n",
    "        print('')\n",
    "        print('KeyboardInterrupt caught; ending training.')\n",
    "    training_history = ny.to_dataframe(training_history)\n",
    "    return training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(dataset, k, model,\n",
    "                    axes=None, figsize=(6,1), dpi=72*4, min_alpha=0.5,\n",
    "                    channels=(0,1,4,5)):\n",
    "    \"\"\"Plots the data, true label, and predicted label (by model) of a dataset.\n",
    "    \n",
    "    `plot_prediction(dataset, k, model)` creates a `matplotlib` figure for\n",
    "    `dataset[k]` (i.e., the `k`th subject/image in `dataset`). The `axes` are\n",
    "    always returned.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : HCPVisualDataset\n",
    "        The dataset used to plot the predictions. This may alternately be a\n",
    "        PyTorch dataloader, in which case the dataloader's dataset must be an\n",
    "        `HCPVisualDataset` object.\n",
    "    k : int\n",
    "        The sample number or subject ID to plot. A sample number is just the\n",
    "        index number for the subject in the dataset; if a number less than 1000\n",
    "        is given, then it is assumed to eb a subject index, while if it is over\n",
    "        1000, it is assumed to be a subject ID.\n",
    "    model : PyTorch Module\n",
    "        A UNet model or other PyTorch model that makes a segmentation\n",
    "        of the images from the given `dataset`.\n",
    "    axes : MatPlotLib axes or `None`, optional\n",
    "        A set of axes onto which to plot the predictions. Must have a total\n",
    "        flattened length of 3.\n",
    "    figsize : tuple, optional\n",
    "        A tuple of `(width, height)` in inches to use for the figure size. This\n",
    "        is ignored if `axes` is provided. The default is `(6, 1)`.\n",
    "    dpi : int, optional\n",
    "        The number of dots per inch in the output image. If `axes` is provided,\n",
    "        this option is ignored. The default is `72 * 4`.\n",
    "    min_alpha : float, optional\n",
    "        The minimum alpha value to show in the alpha channel of the image.\n",
    "        Values below this level are replaced by the formula\n",
    "        `adjusted_value = value * (1 - min_alpha) + min_alpha`. The default is\n",
    "        `0.5`.\n",
    "    channels : iterable of ints, optional\n",
    "        When a dataset whose input images have more than 4 image channels is\n",
    "        provided (i.e., the `'both'` datasets, which have 4 anatomical and 4\n",
    "        functional image layers), then this list of 4 channels is used. By\n",
    "        default this is `(0,1,4,5)`. This option is ignored if the dataset\n",
    "        contains images with only 4 channels.\n",
    "    \"\"\"\n",
    "    if k > 1000:\n",
    "        # We have a subject-ID instead of an index.\n",
    "        k = np.where(dataset.sids == k)[0]\n",
    "    (imdat, imlbl) = dataset[k]\n",
    "    impre = model(imdat[None,:,:,:].float())\n",
    "    if not model.apply_sigmoid:\n",
    "        impre = torch.sigmoid(impre)\n",
    "    impre = dataset.inv_transform(None, impre.detach()[0])\n",
    "    (imdat, imlbl) = dataset.inv_transform(imdat, imlbl)\n",
    "    if axes is None:\n",
    "        (fig,axes) = plt.subplots(1, 3, figsize=figsize, dpi=dpi)\n",
    "    # with imdat we want to adjust the alpha layer\n",
    "    imdat = np.array(imdat)\n",
    "    imdat[:,:,3] = imdat[:,:,3]*(1 - min_alpha) + min_alpha\n",
    "    for (ax,im) in zip(axes, [imdat, imlbl, impre]):\n",
    "        if im.shape[2] > 4: im = im[:,:,:4]\n",
    "        ax.imshow(np.clip(im, 0, 1))\n",
    "        ax.axis('off')\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define our standard training plan for training models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_plan = [\n",
    "    dict(lr=0.00375, gamma=0.9, num_epochs=10,  bce_weight=0.67),\n",
    "    dict(lr=0.00250, gamma=0.9, num_epochs=10,  bce_weight=0.33),\n",
    "    dict(lr=0.00125, gamma=0.9, num_epochs=10,  bce_weight=0.00)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we define a standard set of training and validation subjects. If the files `training_sids.json` and `validate_sids.json` are found in the current directory, they are imported; otherwise, a random partition is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.isfile('training_sids.json') and\n",
    "    os.path.isfile('validate_sids.json')):\n",
    "    with open('training_sids.json', 'r') as fl:\n",
    "        trn_sids = np.array(json.load(fl))\n",
    "    with open('validate_sids.json', 'r') as fl:\n",
    "        val_sids = np.array(json.load(fl))\n",
    "else:\n",
    "    (trn_sids, val_sids) = va.partition(va.sids)\n",
    "    # The following can be used to save these out to files.\n",
    "    #with open('training_sids.json', 'w') as fl:\n",
    "    #    json.dump(trn_sids.tolist(), fl)\n",
    "    #with open('validate_sids.json', 'w') as fl:\n",
    "    #    json.dump(val_sids.tolist(), fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/visual-autolabel/data'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cache_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic options:\n",
    "opts = dict(partition=(trn_sids, val_sids),\n",
    "            model_cache_path=model_cache_path,\n",
    "            data_cache_path=data_cache_path)\n",
    "# We store the results in these dictionaries.\n",
    "models = {}\n",
    "losses = {}\n",
    "dice = {}\n",
    "# Run one modelplan for each feature type.\n",
    "for feat in ('anat', 'func', 'both'):\n",
    "    print(\"=\"*85)\n",
    "    print(f\"Training: {feat}\")\n",
    "    print(\"\")\n",
    "    r = va.run_modelplan(training_plan,\n",
    "                         features=feat,\n",
    "                         **opts)\n",
    "    print(\"\")\n",
    "    models[feat] = r[0]\n",
    "    losses[feat] = r[1]\n",
    "    dice[feat] = r[2]\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Train Continuously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we train the model continuously until an interruption is received (typically a keyboard interruption, which can be sent via the `Kernel > Interrupt Kernel` menu item in Jupyter. This slowly produces a lot of output, but the result, which is returned once the interrupt is sent, will be a `pandas` dataframe of training statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = train_until(training_plan, model_key='2022-04-15_01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What feature-set do we want to plot?\n",
    "features = 'anat'\n",
    "# What model are we plotting the results for?\n",
    "model = \n",
    "# Which subject-IDs (or subject indices, either one) are we plotting?\n",
    "plot_subs = np.arange(6)\n",
    "# Training or Validation data?\n",
    "phase = 'val'\n",
    "\n",
    "# Make the figure and axes that we're going to use.\n",
    "(fig,axs) = plt.subplots(len(plot_idcs), 3, figsize=(6, len(plot_subs)), dpi=72*4)\n",
    "# And plot each row using the `plot_prediction` function.\n",
    "for (axrow,idx) in zip(axs, plot_subs):\n",
    "    plot_prediction(datasets[features][phase], idx, model, axes=axrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code needs to be checked and updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model = trained_models['func'][0]\n",
    "anat_model = trained_models['anat'][0]\n",
    "\n",
    "func_ds = datasets['val']['func']\n",
    "anat_ds = datasets['val']['anat']\n",
    "\n",
    "def npdice(a,b):\n",
    "    a = torch.tensor(a.T[:3])\n",
    "    b = torch.tensor(b.T[:3])\n",
    "    return 1 - dice_loss(a[None,:,:,:], b[None,:,:,:])\n",
    "def subdice(ds, k, model):\n",
    "    sid = ds.sids[k]\n",
    "    (trnim, ansim) = ds[k]\n",
    "    preim = torch.sigmoid(model(trnim[None,:,:,:].float()))\n",
    "    preim = ds.inv_transform(None, preim.detach()[0])\n",
    "    (trnim, ansim) = ds.inv_transform(trnim, ansim)\n",
    "    infim = comparison_image(sid)\n",
    "    priim = companat_image()\n",
    "    return {'model': npdice(preim, ansim),\n",
    "            'bayes': npdice(infim, ansim),\n",
    "            'prior': npdice(priim, ansim)}\n",
    "def alldice(ds, model):\n",
    "    dat = [subdice(ds, k, model) for k in range(len(ds.sids))]\n",
    "    res = []\n",
    "    for (m,sid) in zip(dat, ds.sids):\n",
    "        m = {k:v.detach().numpy() for (k,v) in m.items()}\n",
    "        m['sid'] = sid\n",
    "        res.append(m)\n",
    "    return ny.util.to_dataframe(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = alldice(anat_ds, anat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': (0.7586430125225625,\n",
       "  0.008477384465692323,\n",
       "  0.7724644373568392,\n",
       "  0.7247349369185487,\n",
       "  0.8021125891625124),\n",
       " 'bayes': (0.7087995141025225,\n",
       "  0.009643316660442929,\n",
       "  0.7249986218068809,\n",
       "  0.6947594585447514,\n",
       "  0.7440246912721558),\n",
       " 'prior': (0.6983875593065093,\n",
       "  0.0077295654142980575,\n",
       "  0.7006973293733195,\n",
       "  0.6724228998098741,\n",
       "  0.7331302495354244)}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: (np.mean(v), np.std(v)/np.sqrt(len(v)), np.median(v), np.percentile(v, 25), np.percentile(v, 75))\n",
    " for k in ['model','bayes','prior']\n",
    " for v in [d[k].values]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code needs to be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'dataset': ['both'],\n",
    "    'batch_size': [2,5,8],\n",
    "    'lr': [0.01,0.005,0.00375,0.0025,0.00125],\n",
    "    'gamma': [0.95, 0.9, 0.75, 0.5, 0.25],\n",
    "    'pretrained_resnet': [True, False]}\n",
    "\n",
    "grid = []\n",
    "for (k,vs) in grid_params.items():\n",
    "    if len(grid) == 0:\n",
    "        grid = [{k:v} for v in vs]\n",
    "    else:\n",
    "        grid = [dict(u, **{k:v}) for u in grid for v in vs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "os.nice(10) # run these nicely!\n",
    "cpath0 = os.path.join(resnet_path, 'grid')\n",
    "\n",
    "for (ii,row) in enumerate(grid):\n",
    "    if ii % 12 == 0:\n",
    "        print(\"%3d of %-3d (%6.2f%%)\" % (ii+1, len(grid), ii/(len(grid)-1)*100))\n",
    "    tag = 'dat%04d' % (ii,)\n",
    "    cpath = os.path.join(cpath0, tag)\n",
    "    cfile = os.path.join(cpath0, tag + '.json')\n",
    "    if os.path.isfile(cfile):\n",
    "        for (k,v) in ny.load(cfile).items():\n",
    "            row[k] = v\n",
    "        continue\n",
    "    mdl0 = resnet_model(pretrained=row['pretrained'])\n",
    "    (mdl,loss,dice) = plan_to_model(mdl0, [row], cache_path=cpath, logger=None)\n",
    "    row['tag'] = tag\n",
    "    row['loss'] = loss\n",
    "    row['dice'] = dice\n",
    "    # Clear out the files that we don't need and resave the model and data\n",
    "    ny.save(cfile, row)\n",
    "    shutil.move(os.path.join(cpath,  'round01', 'optim000019.pkl'),\n",
    "                os.path.join(cpath0, 'opt%04d.pkl' % ii))\n",
    "    shutil.move(os.path.join(cpath,  'round01', 'model000019.pkl'),\n",
    "                os.path.join(cpath0, 'mdl%04d.pkl' % ii))\n",
    "    shutil.rmtree(cpath)    \n",
    "    \n",
    "grid = ny.to_dataframe(grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Noah's Python Environment",
   "language": "python",
   "name": "python-nben"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

#! /usr/bin/env python3
# -*- coding: utf-8 -*-

"""Runs the `visual_autolabel.train` module as a command-line interface for the
`visual_autolabel.HCPLinesDataset`.

This script trains UNet models by running the `visual_autolabel.train_until`
function.  This function trains a single set of models a certain number of times
and to save the results out to a cache directory.

The script requires two command-line arguments. The first argument must be a tag
for the model (the model key), the second argument must be a filename of a JSON
file containing the training options, and the third argument must be the
filename of a JSON file containing the training plan. Note that the options file
specifies the cache directories for the models and the dataset.

If DWI-based features need to be generated by the script, then the environment
variable `"DWI_FILENAME_PATTERN"` must be set to an appropriate filename pattern
where the pattern is formatted via `pattern_string.format(**data)` where `data
is a dictionary of the target data (`'rater'` and `'subject'`) combined with the
keys `'hemisphere'` and `'tract_name'`.  For example:
`DWI_FILENAME_PATTERN='/tracts/{subject}/{hemisphere}.{tract_name}.mgz`.
"""

#===============================================================================
# Initialization

#-------------------------------------------------------------------------------
# Dependencies

import os, sys, json

import pimms
import pandas
import numpy as np
import scipy as sp
import nibabel as nib
import pyrsistent as pyr
import neuropythy as ny
import torch, torchvision, torchsummary
import matplotlib as mpl
import matplotlib.pyplot as plt
import ipyvolume as ipv
import neuropythy as ny

import visual_autolabel as va
from visual_autolabel import (
    train_until,
    load_training,
    autolog
)
from visual_autolabel.plot import (
    add_inferred,
    add_prior,
    add_raterlabels
)


#-------------------------------------------------------------------------------
# Initialization

# DWI Features .................................................................
# If the DWI_FILENAME_PATTERN environment variable is set, extract it.
dwi_filename_pattern = os.environ.get('DWI_FILENAME_PATTERN')
# Diffusion-weighted feature code; though in fairness, this is largely just code
# for loading the feature from a file.
class DWIFeature(va.FlatmapFeature):
    """Flatmap features loaded from DWI-based surface data files.
    
    This class provides instructions to the `visual_autolabel` library on how to
    load diffusion-weighted imaging data for use in training PyTorch models. The
    class can be configured by setting the static field `filename_pattern`. This
    field may be a string or a tuple of strings; in either case, all strings are
    first formatted with a dictionary containing all target data as well as the
    `hemisphere` name. If the field is a tuple, then the elements of the tuple
    are joined using `os.path.join`. (The `get_filename` classmethod may
    alternately be rewritten or overloaded.)
    """
    # DWI Filenames ------------------------------------------------------------
    # The filename pattern that we use:
    filename_pattern = dwi_filename_pattern
    # The method to interpret that filename pattern.
    def get_filename(self, target, view):
        data = dict(target, **view)
        data['tract_name'] = self.tract_name
        flpatt = self.filename_pattern
        if isinstance(flpatt, str):
            return flpatt.format(**data)
        else:
            flparts = [s.format(**data) for s in flpatt]
            return os.path.join(*flparts)
    # FlatmapFeature overloads -------------------------------------------------
    __slots__ = ('tract_name')
    def __init__(self, tract_name, interp_method=None):
        super().__init__(f'dwi_{tract_name}', interp_method=interp_method)
        self.tract_name = tract_name
    def get_property(self, fmap, target, view={}):
        # Here's the filename:
        filename = self.get_filename(target, view)
        try:
            prop = ny.load(filename)
        except ValueError:
            from warnings import warn
            # If we fail to load the file, we instead give it blank data.
            warn(f"failed to load '{self.property}' file: {filename}")
            prop = np.zeros(np.max(fmap.labels) + 1, dtype=float)
        return prop[fmap.labels]
# Given this type for loading features, we can now make a dictionary of features
# that we will enable the visual_autolabel library to use.
dwi_features = {
    'dwi_OR': DWIFeature('OR'),
    'dwi_VOF': DWIFeature('VOF')
}
features = dict(
    dwi_features,
    # Add in the 'zeros' feature, which represents all zeros for a null input.
    zeros=va.NullFeature('zeros')
)

# Training Feature Sets.........................................................
# The base feature-sets we are predicting:
vaonly_properties = ('V1', 'V2', 'V3')
econly_properties = ('E0', 'E1', 'E2', 'E3', 'E4')
# The base feature-sets we use to predict the above labels:
t1only_properties = ('x', 'y', 'z',
                     'curvature', 'convexity',
                     'thickness', 'surface_area')
t2only_properties = ('myelin',)
fnonly_properties = ('prf_x', 'prf_y', 'prf_sigma', 'prf_cod')
dwonly_properties = ('dwi_OR', 'dwi_VOF')
full_properties = (t1only_properties + t2only_properties +
                   dwonly_properties + fnonly_properties)
# The feature-sets by name.
input_properties = {
    'null': ('zeros',),
    'anat': t1only_properties,
    't1t2': t1only_properties + t2only_properties,
    'func': t1only_properties + fnonly_properties,
    'trac': t1only_properties + dwonly_properties,
    'not2': t1only_properties + fnonly_properties + dwonly_properties,
    'nofn': t1only_properties + t2only_properties + dwonly_properties,
    'nodw': t1only_properties + t2only_properties + fnonly_properties,
    'full': full_properties
}
output_properties = {
    'area': vaonly_properties,
    'ring': econly_properties,
    'sect': vaonly_properties + econly_properties,
}
# All the feature properties.
properties = dict(input_properties, **output_properties)

# Commandline Arguments.........................................................
# There must be three of them.
if len(sys.argv) != 4:
    print("SYNTAX: train.py <model_key> <options.json> <plan.json>",
          file=sys.stderr)
    sys.exit(1)
model_key = sys.argv[1]
opts_filename = os.path.expanduser(os.path.expandvars(sys.argv[2]))
plan_filename = os.path.expanduser(os.path.expandvars(sys.argv[3]))
try:
    with open(opts_filename, 'rt') as fl:
        opts = json.load(fl)
except Exception as e:
    print(f"Error reading options file ({opts_filename})\n{str(e)}",
          file=sys.stderr)
    sys.exit(2)
try:
    with open(plan_filename, 'rt') as fl:
        plan = json.load(fl)
except Exception as e:
    print(f"Error reading plan file ({plan_filename})\n{str(e)}",
          file=sys.stderr)
    sys.exit(2)

# Options Parsing...............................................................
inputs = opts.pop('inputs', None)
if inputs is None:
    inputs = input_properties
elif isinstance(inputs, str):
    if inputs == 'all':
        inputs = input_properties
    else:
        inputs = input_properties[inputs]
else:
    # Otherwise we leave them as-is! A dictionary or a list could be provided.
    pass
outputs = opts.pop('prediction', 'area')
outputs = output_properties[outputs]


#===============================================================================
# Training

# Make an auto-logger with a log-file.
mcp = opts.get('model_cache_path')
if mcp is not None:
    log_path = os.path.join(mcp, model_key, 'training.log')
    log = autolog(log_path, clear=True)

# Train the model. #TODO: Won't this overwrite the options json?o
train_until(
    inputs, outputs, plan,
    model_key=model_key,
    features=features,
    logger=log,
    **opts
)

# Exit nicely.
sys.exit(0)

